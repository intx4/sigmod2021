{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a2066b67",
   "language": "python",
   "display_name": "PyCharm (sigmod-2021)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "g6Wjqcnc6oEe"
   },
   "source": [
    "!pip install pyspark graphframes"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: graphframes in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (0.6)\r\n",
      "Requirement already satisfied: nose in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from graphframes) (1.3.7)\r\n",
      "Requirement already satisfied: numpy in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from graphframes) (1.19.5)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from pyspark) (0.10.9)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yB4SXU_m7w-Q"
   },
   "source": [
    "!export PYSPARK_SUBMIT_ARGS='--packages graphframes:graphframes:0.8.1-spark3.0-s_2.12'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "brY-5_-X6g6p"
   },
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import tensorflow_hub as hub\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql import Window as w\n",
    "from graphframes import GraphFrame\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer, CountVectorizer, StopWordsRemover, NGram, Normalizer, VectorAssembler, Word2Vec, Word2VecModel, PCA\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UqZuRaaW6g6r"
   },
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config('spark.executor.memory', '4g')\n",
    "    .config('spark.app.name', 'Spark Updated Conf')\n",
    "    .config('spark.executor.cores', '2')\n",
    "    .config('spark.cores.max', '2')\n",
    "    .config('spark.driver.memory','8g')\n",
    "    .getOrCreate()\n",
    ")"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "uB4VNsak6g6t"
   },
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PaEElmjg6g6u"
   },
   "source": [
    "df = spark.read.csv(\"./data/X2.csv\", header=True)\n",
    "df.toPandas()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                  instance_id  \\\n0    www.softwarecity.ca//737   \n1    www.isupplyhub.com//1256   \n2     www.isupplyhub.com//326   \n3     www.isupplyhub.com//821   \n4     www.isupplyhub.com//157   \n..                        ...   \n338       www.vology.com//873   \n339       www.vology.com//823   \n340      www.vology.com//2723   \n341      www.vology.com//1349   \n342      www.vology.com//3017   \n\n                                                 brand  \\\n0                                               Lenovo   \n1                                                 Acer   \n2                                                 Acer   \n3                                                   HP   \n4                                                 Asus   \n..                                                 ...   \n338  Lenovo ThinkPad X230 2320 - 12.5 '' - Core i5 ...   \n339  Lenovo ThinkPad X230 2325 - 12.5 '' - Core i5 ...   \n340  Lenovo ThinkPad X230 Tablet 3438 - 12.5 '' - C...   \n341  Lenovo ThinkPad X230 2324 - 12.5 '' - Core i5 ...   \n342  Lenovo ThinkPad X230 2320 - 12.5 '' - Core i7 ...   \n\n                                             cpu_brand  \\\n0                                      Intel. i5-3320M   \n1           1.6 GHz Intel Core i5-4200U. Intel Core I5   \n2                 1.6 GHz Intel Core i5. Intel Core I5   \n3                                                 None   \n4                         1.7 GHz Core i5-3317U. Intel   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                             cpu_model  \\\n0                                             i5-3320M   \n1                                                 None   \n2                                                 None   \n3                                                 None   \n4                                                 None   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                              cpu_type  \\\n0                        Dual-core ( 2 Core ). Core i5   \n1                          1.6 GHz Intel Core i5-4200U   \n2                                1.6 GHz Intel Core i5   \n3                                                 None   \n4                                1.7 GHz Core i5-3317U   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                         cpu_frequency  \\\n0                                             2.60 GHz   \n1                          1.6 GHz Intel Core i5-4200U   \n2                                1.6 GHz Intel Core i5   \n3                                                 None   \n4                                1.7 GHz Core i5-3317U   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                          ram_capacity  \\\n0                                                 None   \n1                                     8 GB DDR3L SDRAM   \n2                                      4 GB DDR3-SDRAM   \n3                                      4 GB SDRAM DDR3   \n4                                            4 GB DDR3   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                              ram_type  \\\n0          DDR3 SDRAM. DDR3-1600/PC3-12800. DDR3 SDRAM   \n1                         DDR3 SDRAM. 8 GB DDR3L SDRAM   \n2                          DDR3 SDRAM. 4 GB DDR3-SDRAM   \n3                          DDR3 SDRAM. 4 GB SDRAM DDR3   \n4                                DDR3 SDRAM. 4 GB DDR3   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                         ram_frequency  \\\n0                                  DDR3-1600/PC3-12800   \n1                                                 None   \n2                                                 None   \n3                                                 None   \n4                                                 None   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                          hdd_capacity  \\\n0                                               320 GB   \n1                         500 GB mechanical_hard_drive   \n2                         500 GB mechanical_hard_drive   \n3                                               500 GB   \n4                                               256 MB   \n..                                                 ...   \n338  180 GB SSD. 180 GB SSD. Lenovo ThinkPad X230 2...   \n339  500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...   \n340  500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...   \n341  320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm. ...   \n342  256 GB SSD - Self Encrypting Drive. 256 GB SSD...   \n\n                                          ssd_capacity           weight  \\\n0                                                 None          1.80 kg   \n1                                                 None       4.8 pounds   \n2                                                 None       5.2 pounds   \n3                                                 None       4.8 pounds   \n4                                                 None       2.9 pounds   \n..                                                 ...              ...   \n338                             180 GB SSD. 180 GB SSD  3.3 lbs 3.3 lbs   \n339       500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm  3.3 lbs 3.3 lbs   \n340       500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm      4 lbs 4 lbs   \n341       320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm  3.3 lbs 3.3 lbs   \n342  256 GB SSD - Self Encrypting Drive. 256 GB SSD...  3.3 lbs 3.3 lbs   \n\n                                     dimensions  \\\n0                                          None   \n1                   15.02 x 10.08 x 0.90 inches   \n2                      15.02 x 10.08 x 1 inches   \n3                   15.18 x 0.89 x 10.16 inches   \n4                    8.80 x 0.70 x 12.80 inches   \n..                                          ...   \n338  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n339  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n340  9 in. 12 in x 9 in x 1.2 in. 1.2 in. 12 in   \n341  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n342  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n\n                                                 title  \n0    \"Lenovo Thinkpad X230 34352jf Tablet Pc - 12.5...  \n1    Amazon.com : Acer Aspire V7-582PG-6479 15.6-In...  \n2    Amazon.com : Acer Aspire E1-572-6870 15.6 Inch...  \n3    \"Amazon.com : 15.6\"\" HP 15-f009wm Amd Dual-Cor...  \n4    Amazon.com : ASUS UX31A-XB52 13.3-Inch Ultrabo...  \n..                                                 ...  \n338  \"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i5 ...  \n339  \"Lenovo ThinkPad X230 2325 - 12.5\"\" - Core i5 ...  \n340  \"Lenovo ThinkPad X230 Tablet 3438 - 12.5\"\" - C...  \n341  \"Lenovo ThinkPad X230 2324 - 12.5\"\" - Core i5 ...  \n342  \"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i7 ...  \n\n[343 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instance_id</th>\n      <th>brand</th>\n      <th>cpu_brand</th>\n      <th>cpu_model</th>\n      <th>cpu_type</th>\n      <th>cpu_frequency</th>\n      <th>ram_capacity</th>\n      <th>ram_type</th>\n      <th>ram_frequency</th>\n      <th>hdd_capacity</th>\n      <th>ssd_capacity</th>\n      <th>weight</th>\n      <th>dimensions</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>www.softwarecity.ca//737</td>\n      <td>Lenovo</td>\n      <td>Intel. i5-3320M</td>\n      <td>i5-3320M</td>\n      <td>Dual-core ( 2 Core ). Core i5</td>\n      <td>2.60 GHz</td>\n      <td>None</td>\n      <td>DDR3 SDRAM. DDR3-1600/PC3-12800. DDR3 SDRAM</td>\n      <td>DDR3-1600/PC3-12800</td>\n      <td>320 GB</td>\n      <td>None</td>\n      <td>1.80 kg</td>\n      <td>None</td>\n      <td>\"Lenovo Thinkpad X230 34352jf Tablet Pc - 12.5...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>www.isupplyhub.com//1256</td>\n      <td>Acer</td>\n      <td>1.6 GHz Intel Core i5-4200U. Intel Core I5</td>\n      <td>None</td>\n      <td>1.6 GHz Intel Core i5-4200U</td>\n      <td>1.6 GHz Intel Core i5-4200U</td>\n      <td>8 GB DDR3L SDRAM</td>\n      <td>DDR3 SDRAM. 8 GB DDR3L SDRAM</td>\n      <td>None</td>\n      <td>500 GB mechanical_hard_drive</td>\n      <td>None</td>\n      <td>4.8 pounds</td>\n      <td>15.02 x 10.08 x 0.90 inches</td>\n      <td>Amazon.com : Acer Aspire V7-582PG-6479 15.6-In...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>www.isupplyhub.com//326</td>\n      <td>Acer</td>\n      <td>1.6 GHz Intel Core i5. Intel Core I5</td>\n      <td>None</td>\n      <td>1.6 GHz Intel Core i5</td>\n      <td>1.6 GHz Intel Core i5</td>\n      <td>4 GB DDR3-SDRAM</td>\n      <td>DDR3 SDRAM. 4 GB DDR3-SDRAM</td>\n      <td>None</td>\n      <td>500 GB mechanical_hard_drive</td>\n      <td>None</td>\n      <td>5.2 pounds</td>\n      <td>15.02 x 10.08 x 1 inches</td>\n      <td>Amazon.com : Acer Aspire E1-572-6870 15.6 Inch...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>www.isupplyhub.com//821</td>\n      <td>HP</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>4 GB SDRAM DDR3</td>\n      <td>DDR3 SDRAM. 4 GB SDRAM DDR3</td>\n      <td>None</td>\n      <td>500 GB</td>\n      <td>None</td>\n      <td>4.8 pounds</td>\n      <td>15.18 x 0.89 x 10.16 inches</td>\n      <td>\"Amazon.com : 15.6\"\" HP 15-f009wm Amd Dual-Cor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>www.isupplyhub.com//157</td>\n      <td>Asus</td>\n      <td>1.7 GHz Core i5-3317U. Intel</td>\n      <td>None</td>\n      <td>1.7 GHz Core i5-3317U</td>\n      <td>1.7 GHz Core i5-3317U</td>\n      <td>4 GB DDR3</td>\n      <td>DDR3 SDRAM. 4 GB DDR3</td>\n      <td>None</td>\n      <td>256 MB</td>\n      <td>None</td>\n      <td>2.9 pounds</td>\n      <td>8.80 x 0.70 x 12.80 inches</td>\n      <td>Amazon.com : ASUS UX31A-XB52 13.3-Inch Ultrabo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>www.vology.com//873</td>\n      <td>Lenovo ThinkPad X230 2320 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>180 GB SSD. 180 GB SSD. Lenovo ThinkPad X230 2...</td>\n      <td>180 GB SSD. 180 GB SSD</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>www.vology.com//823</td>\n      <td>Lenovo ThinkPad X230 2325 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2325 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>www.vology.com//2723</td>\n      <td>Lenovo ThinkPad X230 Tablet 3438 - 12.5 '' - C...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm</td>\n      <td>4 lbs 4 lbs</td>\n      <td>9 in. 12 in x 9 in x 1.2 in. 1.2 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 Tablet 3438 - 12.5\"\" - C...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>www.vology.com//1349</td>\n      <td>Lenovo ThinkPad X230 2324 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm. ...</td>\n      <td>320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2324 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>www.vology.com//3017</td>\n      <td>Lenovo ThinkPad X230 2320 - 12.5 '' - Core i7 ...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>256 GB SSD - Self Encrypting Drive. 256 GB SSD...</td>\n      <td>256 GB SSD - Self Encrypting Drive. 256 GB SSD...</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i7 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>343 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "nj-gVsHx6g6v"
   },
   "source": [
    "# 0. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Pasvnmhd6g6w"
   },
   "source": [
    "\"\"\"\n",
    "Job:\n",
    "    1 - remove ssd capacity, dimensions\n",
    "    2 - infer brand from title\n",
    "    3 - infer cpu brand and type\n",
    "    4 - uniform weights\n",
    "\"\"\"\n",
    "# Set everything to lowercase\n",
    "for c in df.columns:\n",
    "    df = df.withColumn(c, f.lower(f.col(c)))\n",
    "\n",
    "df = df.drop('ssd_capacity')\n",
    "df = df.drop('dimensions')\n",
    "# Extract brand or infer from title\n",
    "df = df.withColumn('brand', f.regexp_extract('brand', \"^(\\w+)\", 0))\n",
    "computer_brands = ['lenovo', 'acer', 'hp', 'dell', 'asus', 'samsung', 'huawei', 'surface', 'apple']\n",
    "computer_brands_pattern = '({})'.format('|'.join(computer_brands))\n",
    "df = df.withColumn('brand', f.when( f.regexp_extract('title', computer_brands_pattern, 0)!='', f.regexp_extract('title', computer_brands_pattern, 0))\\\n",
    "                   .otherwise(df.brand))\n",
    "#exctract cpu_brand and infer type if intel\n",
    "cpu_brands = ['intel', 'apple', 'amd', 'nvidia', 'arm']\n",
    "cpu_pattern = '({})'.format('|'.join(cpu_brands))\n",
    "df = df.withColumn('cpu_model',f.regexp_extract('cpu_model', '(i\\d|pentium|celeron|a\\d)', 0))\n",
    "df = df.withColumn('cpu_model', f.when( (f.regexp_extract('cpu_brand','(intel|amd)', 0 )!='') & f.isnull(df.cpu_model) ,\\\n",
    "                                        f.regexp_extract('cpu_brand', '(i\\d|pentium|celeron|a\\d)', 0))\\\n",
    "                   .otherwise(df.cpu_model))\n",
    "df = df.withColumn('cpu_brand', f.when(f.regexp_extract('cpu_brand', cpu_pattern, 0) != '', f.regexp_extract('cpu_brand', cpu_pattern, 1))\\\n",
    "                                       .otherwise(f.regexp_extract('title', cpu_pattern, 0)))\n",
    "#convert weight from pounds to kilos\n",
    "df = df.withColumn('weight', f.when(df.weight.contains('pounds') | df.weight.contains('lbs'),\n",
    "                                    (f.regexp_extract('weight', '(\\d+.?\\d)', 0).cast(t.DoubleType()))).otherwise(\n",
    "                                    f.round(f.regexp_extract('weight', '(\\d+.?\\d)', 0).cast(t.DoubleType())*2.20462,1)\n",
    "                        )\n",
    "                    )"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tNIZDK-K-EGd"
   },
   "source": [
    "\"\"\"\n",
    "merge ram columns and cpu columns into one for ram and one for cpu\n",
    "\"\"\"\n",
    "#from more_itertools import intersperse\n",
    "\n",
    "def merge_columns(df, column_names, output):\n",
    "    df = df.withColumn(output, f.concat_ws(\" \", *column_names))\n",
    "    return df.drop(*column_names)\n",
    "\n",
    "ddf = df.drop(\"ram_frequency\")\n",
    "ddf = merge_columns(ddf, [\"cpu_brand\", \"cpu_model\", \"cpu_frequency\", \"cpu_type\"], \"cpu\")\n",
    "ddf = merge_columns(ddf, [\"ram_capacity\", \"ram_type\"], \"ram\")\n",
    "ddf.columns"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['instance_id', 'brand', 'hdd_capacity', 'weight', 'title', 'cpu', 'ram']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5lLUdrr6g6w"
   },
   "source": [
    "# 1. Blocking\n",
    "Blocking will be done feeding a TF-IDF matrix to an LDA model and extracting\n",
    "keywords from the title matching them to topics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qEBkED7C6g6x"
   },
   "source": [
    "@f.udf(returnType=t.ArrayType(t.StringType()))\n",
    "def filter_alnum(arr):\n",
    "    return [t for t in arr if t.isalnum() and len(t) > 2]\n",
    "\n",
    "\"\"\"Returns the df with tokenized columns with stopwords removed\"\"\"\n",
    "def tokenize(df, string_cols):\n",
    "    output = df\n",
    "    stopW = ['softwarecity', 'amazon', 'com', 'pc', 'windows', 'computers', 'computer', 'accessories', 'laptop', 'notebook', 'kg', 'inch', 'processor', 'memory','gb', 'ram', 'hdd', 'ssd', 'cpu', 'display', 'hz', 'ghz', 'tb','rpm', 'slot', 'slots', 'mhz', 'cache', 'ram', 'ddram', 'dram', 'hd']\n",
    "    for c in string_cols:\n",
    "        output = output.withColumn('temp', f.coalesce(f.col(c), f.lower(c), f.lit('')))\n",
    "        tokenizer = RegexTokenizer(inputCol='temp', outputCol=c+\"_rawtokens\", pattern = \"\\\\W\")\n",
    "        remover = StopWordsRemover(inputCol=c+\"_rawtokens\", outputCol=c+\"_tokens\", stopWords=stopW)\n",
    "\n",
    "        output = tokenizer.transform(output)\n",
    "        output = remover.transform(output).drop(c+\"_rawtokens\")\n",
    "        output = output.withColumn(c+'_tokens', f.array_distinct(filter_alnum(f.col(c+\"_tokens\"))))\n",
    "    # output has c+tokens columns\n",
    "    return output.drop(\"temp\")\n",
    "\n",
    "def generate_blocking_keys(df, token_cols, min_freq=1):\n",
    "    \"\"\"Pipeline:\n",
    "            1 - CountVectorizer -> TF\n",
    "            2 - IDF\n",
    "            3 - LDA\n",
    "    \"\"\"\n",
    "    # merge all tokens in one column + merge title and brand for blocking\n",
    "    df = df.withColumn('tokens', f.array_distinct(f.concat(*token_cols)))\\\n",
    "        .drop('cpu_tokens')\\\n",
    "        .drop('ram_tokens')\\\n",
    "        .drop('hdd_capacity_tokens')\\\n",
    "        .drop('weight_tokens')\\\n",
    "        .withColumn('tokens_for_vocab', f.array_distinct(f.concat('title_tokens', 'brand_tokens')))\\\n",
    "        .drop('title_tokens')\\\n",
    "        .drop('brand_tokens')\n",
    "    cv = CountVectorizer(inputCol='tokens_for_vocab', outputCol=\"raw_features\")\n",
    "    cvmodel = cv.fit(df)\n",
    "    df_vect = cvmodel.transform(df)\n",
    "    df_vect = df_vect.drop('tokens_for_vocab')\n",
    "\n",
    "    idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=min_freq)\n",
    "    idfModel = idf.fit(df_vect)\n",
    "    df_idf= idfModel.transform(df_vect)\n",
    "\n",
    "    normalizer = Normalizer(p=2.0, inputCol='features', outputCol='tfidf')\n",
    "    output = normalizer.transform(df_idf)\n",
    "    output = output.drop('raw_features').drop('features')\n",
    "    k = output.select('brand').distinct().count()\n",
    "    lda = LDA(k=k, maxIter=1000, featuresCol='tfidf')\n",
    "    lda_model = lda.fit(output)\n",
    "    vocab = cvmodel.vocabulary\n",
    "\n",
    "    #returns words for each topic term\n",
    "    @f.udf(returnType=t.ArrayType(t.StringType()))\n",
    "    def get_words(token_list):\n",
    "        return [vocab[token_id] for token_id in token_list]\n",
    "\n",
    "    #create list of topic keywords\n",
    "    # i.e topic 1 -> acer, anspire, intel\n",
    "    topics = lda_model.describeTopics(3).withColumn('topicWords', get_words(f.col('termIndices'))).collect()\n",
    "    list_of_topics = []\n",
    "    for r in topics:\n",
    "        topicW = r.__getitem__('topicWords')\n",
    "        for w in topicW:\n",
    "            list_of_topics.append(w)\n",
    "\n",
    "    #returns list of 3 'hashtags' i.e keywords for topic\n",
    "    #from tokens: title, brand, cpu_brand\n",
    "    @f.udf(returnType=t.ArrayType(t.StringType()))\n",
    "    def get_key(words):\n",
    "        l = [w for w in words if w in list_of_topics]\n",
    "        l = list(set(l))\n",
    "        l.sort()\n",
    "        return l[:3]\n",
    "    output = output.withColumn(\"blocking_key\", get_key(f.col(\"tokens\")))\n",
    "    return output\n",
    "\n",
    "\"\"\"Use universal sentence encoder from tensorflow_hub\"\"\"\n",
    "MODEL = None\n",
    "def get_model_magic():\n",
    "  global MODEL\n",
    "  if MODEL is None:\n",
    "      MODEL = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "  return MODEL\n",
    "@f.udf(returnType=VectorUDT())\n",
    "def encode_sentence(x):\n",
    "  model = get_model_magic()\n",
    "  emb = model([x]).numpy()[0]\n",
    "  return Vectors.dense(emb)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ouaaVLVQ6g6y"
   },
   "source": [
    "columns = ['title', 'brand', 'cpu', 'ram', 'hdd_capacity', 'weight']\n",
    "#Generate Blocking Keys\n",
    "\n",
    "blocking_df = tokenize(ddf, columns)\n",
    "blocking_df = generate_blocking_keys(blocking_df, [c+'_tokens' for c in columns])\n",
    "blocking_df.limit(1).show()\n",
    "\n",
    "#columns: [id, brand, hdd_cap , weight, title, cpu, ram, tokens, tfidf, block_key]"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+\n",
      "|         instance_id| brand|hdd_capacity|weight|               title|                 cpu|                 ram|              tokens|               tfidf| blocking_key|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+\n",
      "|www.softwarecity....|lenovo|      320 gb|   4.0|\"lenovo thinkpad ...|intel i5 2.60 ghz...|ddr3 sdram. ddr3-...|[lenovo, thinkpad...|(314,[0,1,2,4,6,7...|[3320m, x230]|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|         instance_id| brand|hdd_capacity|weight|               title|                 cpu|                 ram|              tokens|               tfidf| blocking_key|            encoding|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|www.softwarecity....|lenovo|      320 gb|   4.0|\"lenovo thinkpad ...|intel i5 2.60 ghz...|ddr3 sdram. ddr3-...|[lenovo, thinkpad...|(314,[0,1,2,4,6,7...|[3320m, x230]|[0.03184049949049...|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add encoding on all the columns (not tokenized)\n",
    "cols_to_encode = columns\n",
    "blocking_df = blocking_df.withColumn('to_encode', f.concat(*cols_to_encode))\n",
    "blocking_df = blocking_df.withColumn('encoding', encode_sentence(f.coalesce(f.col('to_encode'), f.lit(''))))\\\n",
    "    .drop('to_encode')\n",
    "\n",
    "blocking_df.limit(1).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "AfgQ2rjy6g6z"
   },
   "source": [
    "blocking_df.groupby('blocking_key').count().show()"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        blocking_key|count|\n",
      "+--------------------+-----+\n",
      "|       [touchscreen]|   10|\n",
      "|         [elitebook]|   20|\n",
      "|                  []|   54|\n",
      "|[cool, silver, to...|    2|\n",
      "|              [x220]|    4|\n",
      "|             [3320m]|    1|\n",
      "|[3320m, 8570p, el...|    3|\n",
      "|            [silver]|    9|\n",
      "|  [2760p, elitebook]|    2|\n",
      "|            [carbon]|   73|\n",
      "|       [3320m, x230]|  110|\n",
      "|        [4291, x220]|    4|\n",
      "|      [cool, silver]|    3|\n",
      "|  [2170p, elitebook]|    3|\n",
      "|[silver, touchscr...|    1|\n",
      "|              [x230]|   27|\n",
      "| [cool, touchscreen]|    3|\n",
      "|               [771]|   11|\n",
      "|   [160, upgradable]|    2|\n",
      "| [elitebook, silver]|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ewM2XlPt6g60"
   },
   "source": [
    "# 2. Candidate pairs generation and match likelihood"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "g_FB3bXg6g60"
   },
   "source": [
    "\"\"\"\n",
    "This cell output a candidates dataframe that has\n",
    "instance_ids pairs that makes sense to compare, i.e each\n",
    "entity will be paired with another entity from the same block\n",
    "\"\"\"\n",
    "# Filter blocks to only keep ones bigger than one\n",
    "pairs = (\n",
    "    blocking_df\n",
    "    .groupby('blocking_key').agg(f.count('instance_id').alias('size'), f.collect_set('instance_id').alias('id'))\\\n",
    "    .filter(f.col('size') > 1).select('blocking_key',f.explode('id').alias('id'))\n",
    ")\n",
    "left = pairs.withColumnRenamed('id', 'src')\n",
    "right = pairs.withColumnRenamed('id', 'dst')\n",
    "#candidates based on matching of blocking_key (i.e inside the block)\n",
    "candidates = left.join(right, ['blocking_key'], 'inner')\\\n",
    "    .filter(f.col('src') < f.col('dst'))\\\n",
    "    .select('src', 'dst').distinct()\n",
    "node = blocking_df.withColumnRenamed('instance_id', 'id')\n",
    "node.limit(1).show()"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|                  id| brand|hdd_capacity|weight|               title|                 cpu|                 ram|              tokens|               tfidf| blocking_key|            encoding|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "|www.softwarecity....|lenovo|      320 gb|   4.0|\"lenovo thinkpad ...|intel i5 2.60 ghz...|ddr3 sdram. ddr3-...|[lenovo, thinkpad...|(314,[0,1,2,4,6,7...|[3320m, x230]|[0.03184049949049...|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+--------------------+--------------------+-------------+--------------------+\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nn_ones_old = labels.filter('label==1').count()\\nn_zeros = labels.filter('label==0').count()\\n\\ntuples = labels.filter('label==1').drop('label').collect()\\nprint(tuples)\\nll = []\\nfor t in tuples:\\n    left = t[0]\\n    right = t[1]\\n    if not ll:\\n        #First initialization\\n        l = []\\n        l.append(left)\\n        l.append(right)\\n        ll.append(l)\\n    #loops all the list to find where to put\\n    found_l = -1\\n    found_r = -1\\n    put = False\\n\\n    for i,l in enumerate(ll):\\n        #store list indexes where occurance happened\\n        if left in l:\\n            found_l = i\\n        if right in l:\\n            found_r = i\\n\\n    if found_l != -1:\\n        if found_r == -1:\\n            ll[found_l].append(right)\\n            put = True\\n    if found_r != -1:\\n        if found_l == -1:\\n            ll[found_r].append(left)\\n            put = True\\n\\n    if found_r != -1 and found_l != -1 and found_l != found_r:\\n        #create new list of list and merge entries\\n        ll_new = []\\n        if found_l <= found_r:\\n            minf = found_l\\n            maxf = found_r\\n        else:\\n            minf = found_r\\n            maxf = found_l\\n\\n        for k in range(0, len(ll)):\\n            if k != maxf:\\n                ll_new.append(ll[k])\\n            if k == minf:\\n                for tp in ll[maxf]:\\n                    if tp not in ll_new[minf]:\\n                        ll_new[minf].append(tp)\\n        ll = ll_new\\n        put = True\\n    if found_r == -1 and found_l == -1:\\n        #new list\\n        l = []\\n        l.append(left)\\n        l.append(right)\\n        ll.append(l)\\n#SAFETY CHECK OK\\nfor i,l in enumerate(ll):\\n    for t in l:\\n        for j in range(0,len(ll)):\\n            if j != i:\\n                if t in ll[j]:\\n                    print('NOOO')\\n\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read label.csv and expand it trough transitivity\n",
    "\"\"\"\n",
    "labels_col = ['lid', 'rid', 'label']\n",
    "labels = (\n",
    "    spark.read.csv(\"./data/Y2.csv\", header=True)\n",
    "    .withColumnRenamed('left_instance_id', 'lid')\n",
    "    .withColumnRenamed('right_instance_id', 'rid')\n",
    ")\n",
    "\"\"\"\n",
    "n_ones_old = labels.filter('label==1').count()\n",
    "n_zeros = labels.filter('label==0').count()\n",
    "\n",
    "tuples = labels.filter('label==1').drop('label').collect()\n",
    "print(tuples)\n",
    "ll = []\n",
    "for t in tuples:\n",
    "    left = t[0]\n",
    "    right = t[1]\n",
    "    if not ll:\n",
    "        #First initialization\n",
    "        l = []\n",
    "        l.append(left)\n",
    "        l.append(right)\n",
    "        ll.append(l)\n",
    "    #loops all the list to find where to put\n",
    "    found_l = -1\n",
    "    found_r = -1\n",
    "    put = False\n",
    "\n",
    "    for i,l in enumerate(ll):\n",
    "        #store list indexes where occurance happened\n",
    "        if left in l:\n",
    "            found_l = i\n",
    "        if right in l:\n",
    "            found_r = i\n",
    "\n",
    "    if found_l != -1:\n",
    "        if found_r == -1:\n",
    "            ll[found_l].append(right)\n",
    "            put = True\n",
    "    if found_r != -1:\n",
    "        if found_l == -1:\n",
    "            ll[found_r].append(left)\n",
    "            put = True\n",
    "\n",
    "    if found_r != -1 and found_l != -1 and found_l != found_r:\n",
    "        #create new list of list and merge entries\n",
    "        ll_new = []\n",
    "        if found_l <= found_r:\n",
    "            minf = found_l\n",
    "            maxf = found_r\n",
    "        else:\n",
    "            minf = found_r\n",
    "            maxf = found_l\n",
    "\n",
    "        for k in range(0, len(ll)):\n",
    "            if k != maxf:\n",
    "                ll_new.append(ll[k])\n",
    "            if k == minf:\n",
    "                for tp in ll[maxf]:\n",
    "                    if tp not in ll_new[minf]:\n",
    "                        ll_new[minf].append(tp)\n",
    "        ll = ll_new\n",
    "        put = True\n",
    "    if found_r == -1 and found_l == -1:\n",
    "        #new list\n",
    "        l = []\n",
    "        l.append(left)\n",
    "        l.append(right)\n",
    "        ll.append(l)\n",
    "#SAFETY CHECK OK\n",
    "for i,l in enumerate(ll):\n",
    "    for t in l:\n",
    "        for j in range(0,len(ll)):\n",
    "            if j != i:\n",
    "                if t in ll[j]:\n",
    "                    print('NOOO')\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nfrom itertools import combinations\\n\\nlabels = labels.filter('label==0')\\nfor l in ll:\\n    for c in combinations(l,2):\\n        left = c[0]\\n        right = c[1]\\n        nR = spark.createDataFrame([(left, right, '1')], labels_col)\\n        labels = labels.union(nR)\\n\\nn_ones_new = labels.filter('label==1').count()\\nprint(f'Ones before expansion: {n_ones_old}')\\nprint(f'Ones after expansion: {n_ones_new}')\\nprint(f'One to zero ratio: {n_ones_new/ n_zeros}')o \""
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from itertools import combinations\n",
    "\n",
    "labels = labels.filter('label==0')\n",
    "for l in ll:\n",
    "    for c in combinations(l,2):\n",
    "        left = c[0]\n",
    "        right = c[1]\n",
    "        nR = spark.createDataFrame([(left, right, '1')], labels_col)\n",
    "        labels = labels.union(nR)\n",
    "\n",
    "n_ones_new = labels.filter('label==1').count()\n",
    "print(f'Ones before expansion: {n_ones_old}')\n",
    "print(f'Ones after expansion: {n_ones_new}')\n",
    "print(f'One to zero ratio: {n_ones_new/ n_zeros}')o \\\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lid', 'rid', 'l_brand', 'l_hdd_capacity', 'l_weight', 'l_title', 'l_cpu', 'l_ram', 'l_tokens', 'l_tfidf', 'l_blocking_key', 'l_encoding', 'r_brand', 'r_hdd_capacity', 'r_weight', 'r_title', 'r_cpu', 'r_ram', 'r_tokens', 'r_tfidf', 'r_blocking_key', 'r_encoding']\n",
      "['lid', 'rid', 'label', 'l_brand', 'l_hdd_capacity', 'l_weight', 'l_title', 'l_cpu', 'l_ram', 'l_tokens', 'l_tfidf', 'l_blocking_key', 'l_encoding', 'r_brand', 'r_hdd_capacity', 'r_weight', 'r_title', 'r_cpu', 'r_ram', 'r_tokens', 'r_tfidf', 'r_blocking_key', 'r_encoding']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reuse this cell to join a <left_id,right_id> with node to extract features\n",
    "\"\"\"\n",
    "\n",
    "columns = [\"id\", \"brand\", \"hdd_capacity\" , \"weight\", \"title\", \"cpu\", \"ram\", \"tokens\", \"tfidf\", \"blocking_key\", \"encoding\"]\n",
    "matching_pairs = candidates.join(node.alias(\"node_1\"), candidates.src == node.id, 'inner').drop('id')\n",
    "for c in columns[1:]:\n",
    "    matching_pairs = matching_pairs.withColumnRenamed(c, 'l_'+c)\n",
    "\n",
    "matching_pairs = matching_pairs.alias('one').join(node.alias(\"node_2\"), matching_pairs.dst == node.id, 'inner').drop('id')\n",
    "for c in columns[1:]:\n",
    "    matching_pairs = matching_pairs.withColumnRenamed(c, 'r_'+c)\n",
    "matching_pairs = matching_pairs.withColumnRenamed('src', 'lid').withColumnRenamed('dst','rid')\n",
    "print(matching_pairs.columns)\n",
    "#label_df = labels.join(candidates.withColumnRenamed('src','lid').withColumnRenamed('dst','rid'), ['lid','rid'], 'inner')\n",
    "label_df = labels.join(node.alias(\"node_1\"), labels.lid == node.id, 'inner').drop('id')\n",
    "for c in columns[1:]:\n",
    "    label_df = label_df.withColumnRenamed(c, 'l_'+c)\n",
    "\n",
    "label_df = label_df.alias('one').join(node.alias(\"node_2\"), label_df.rid == node.id, 'inner').drop('id')\n",
    "for c in columns[1:]:\n",
    "    label_df = label_df.withColumnRenamed(c, 'r_'+c)\n",
    "print(label_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1rMiiAQC6g60"
   },
   "source": [
    "import numpy as np\n",
    "\"\"\"\n",
    "Add some distances as new possible features\n",
    "\"\"\"\n",
    "\n",
    "@f.udf(returnType=t.DoubleType())\n",
    "def dot(x, y):\n",
    "  if x is not None and y is not None:\n",
    "    return float(x.dot(y))\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "\"\"\"\n",
    "Compute the similarity as inner product between\n",
    "left and right encodings\n",
    "\"\"\"\n",
    "@f.udf(returnType=t.DoubleType())\n",
    "def encoding_sim(le, re):\n",
    "    return np.inner(le.toArray(), re.toArray()).item()\n",
    "\n",
    "def levenshtein_sim(c1, c2):\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .otherwise(1 - f.levenshtein(c1, c2) / f.greatest(f.length(c1), f.length(c2)))\n",
    "  return output\n",
    "\n",
    "def num_sim(c1, c2):\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .when((f.col(c1) == 0) & (f.col(c2) == 0), 1)\\\n",
    "            .when((f.col(c1) == 0) | (f.col(c2) == 0), 0)\\\n",
    "            .otherwise(1 - f.abs(f.col(c1) - f.col(c2)) / f.greatest(c1, c2))\n",
    "  return output\n",
    "\n",
    "def token_overlap(c1, c2):\n",
    "  # is the overlap a significant part of the shorter string\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .when((f.size(f.array_distinct(c1)) == 0) | (f.size(f.array_distinct(c2)) == 0), 0)\\\n",
    "            .otherwise(f.size(f.array_intersect(c1, c2)) / f.least(f.size(f.array_distinct(c1)), f.size(f.array_distinct(c1))))\n",
    "  return output\n",
    "\n",
    "def calc_sim(df):\n",
    "    metrics = []\n",
    "    col_lev = [\"brand\", \"hdd_capacity\", \"title\", \"cpu\", \"ram\"]\n",
    "\n",
    "    for c in columns[1:]:\n",
    "        if c in col_lev:\n",
    "            df = df.withColumn(c+'_lev', levenshtein_sim('l_'+c, 'r_'+c))\n",
    "            metrics.append(c+'_lev')\n",
    "        if c == 'tokens':\n",
    "            df = df.withColumn('tokens_overlap', token_overlap('l_tokens', 'r_tokens'))\n",
    "            metrics.append('tokens_overlap')\n",
    "        if c == 'weight':\n",
    "            df = df.withColumn('weight_sim', num_sim('l_weight','r_weight'))\n",
    "            metrics.append('weight_sim')\n",
    "        if c == 'tfidf':\n",
    "            df = df.withColumn('tfidf_sim', dot('l_tfidf','r_tfidf'))\n",
    "            metrics.append('tfidf_sim')\n",
    "        if c == 'encoding':\n",
    "            df = df.withColumn('encoding_sim', encoding_sim('l_encoding','r_encoding'))\n",
    "            metrics.append('encoding_sim')\n",
    "    @f.udf(returnType=t.DoubleType())\n",
    "    def sum_distance(distances):\n",
    "        return sum(d for d in distances if d != None)\n",
    "\n",
    "    df = df.withColumn('sum_sim', sum_distance(f.array(*metrics)))\n",
    "    udf_norm = f.udf(lambda d : d / len(metrics))\n",
    "    df = df.withColumn('overall_sim', udf_norm(f.col('sum_sim'))).drop(f.col('sum_sim'))\n",
    "\n",
    "    return df\n",
    "\n",
    "matching_pairs = calc_sim(matching_pairs)\n",
    "label_df = calc_sim(label_df)\n",
    "label_df.limit(1).show()\n",
    "matching_pairs.limit(1).show()"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+-------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+--------------+--------+--------------------+--------------------+---------+--------------------+--------------------+--------------+--------------------+---------+------------------+----------+------------------+-------------------+------------------+------------------+-------------------+-------------------+-------------------+\n",
      "|                 lid|                 rid|label|l_brand|      l_hdd_capacity|l_weight|             l_title|               l_cpu|               l_ram|            l_tokens|             l_tfidf|l_blocking_key|          l_encoding|r_brand|r_hdd_capacity|r_weight|             r_title|               r_cpu|    r_ram|            r_tokens|             r_tfidf|r_blocking_key|          r_encoding|brand_lev|  hdd_capacity_lev|weight_sim|         title_lev|            cpu_lev|           ram_lev|    tokens_overlap|          tfidf_sim|       encoding_sim|        overall_sim|\n",
      "+--------------------+--------------------+-----+-------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+--------------+--------+--------------------+--------------------+---------+--------------------+--------------------+--------------+--------------------+---------+------------------+----------+------------------+-------------------+------------------+------------------+-------------------+-------------------+-------------------+\n",
      "|www.flexshopper.c...|www.amazon.com//1389|    1|   acer|500 gb hdd / 5400...|     5.2|\"acer aspire e1-5...|intel i3 intel co...|4 gb ddr3l 4 gb d...|[acer, aspire, 57...|(314,[0,1,10,11,1...|            []|[-0.0052821431308...|   acer|        500 gb|    null|\"amazon.com : bra...|intel i3 intel co...|4 gb 4 gb|[brand, new, acer...|(314,[0,11,12,16,...|            []|[-0.0356568209826...|      1.0|0.2857142857142857|       0.0|0.3006134969325154|0.30508474576271183|0.4285714285714286|0.4666666666666667|0.28005275339018026|0.06903575207820162|0.34841545879066554|\n",
      "+--------------------+--------------------+-----+-------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+-------+--------------+--------+--------------------+--------------------+---------+--------------------+--------------------+--------------+--------------------+---------+------------------+----------+------------------+-------------------+------------------+------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "+-------------+--------------------+-------+--------------+--------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+---------+-------------------+------------------+-------------------+------------------+------------------+-------------------+--------------------+------------------+-------------------+\n",
      "|          lid|                 rid|l_brand|l_hdd_capacity|l_weight|             l_title|               l_cpu|            l_ram|            l_tokens|             l_tfidf|l_blocking_key|          l_encoding|r_brand|      r_hdd_capacity|r_weight|             r_title|               r_cpu|               r_ram|            r_tokens|             r_tfidf|r_blocking_key|          r_encoding|brand_lev|   hdd_capacity_lev|        weight_sim|          title_lev|           cpu_lev|           ram_lev|     tokens_overlap|           tfidf_sim|      encoding_sim|        overall_sim|\n",
      "+-------------+--------------------+-------+--------------+--------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+---------+-------------------+------------------+-------------------+------------------+------------------+-------------------+--------------------+------------------+-------------------+\n",
      "|buy.net//1963|www.flexshopper.c...|   acer|          1 tb|     7.0|\"acer aspire v3-7...|intel i7 2.20 ghz...|12 gb ddr3l sdram|[acer, aspire, 77...|(314,[0,1,11,12,1...|            []|[0.00934366881847...|   acer|500 gb hdd / 5400...|     7.1|\"acer aspire e1-7...|intel pentium int...|4 gb ddr3l 4 gb d...|[acer, aspire, 73...|(314,[1,10,11,12,...|            []|[-0.0527827218174...|      1.0|0.09523809523809523|0.9859154929577465|0.24028268551236753|0.2727272727272727|0.5238095238095238|0.16129032258064516|0.026662223666578933|0.5414155149250308|0.42748234793525114|\n",
      "+-------------+--------------------+-------+--------------+--------+--------------------+--------------------+-----------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------+--------------------+---------+-------------------+------------------+-------------------+------------------+------------------+-------------------+--------------------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "trF-IsGj6g62"
   },
   "source": [
    "@f.udf(returnType=VectorUDT())\n",
    "def toList(row):\n",
    "    l = []\n",
    "    for v in row:\n",
    "        for n in v:\n",
    "            l.append(float(n))\n",
    "    return Vectors.dense(l)\n",
    "\n",
    "to_double = f.udf(lambda x: x.toArray()[0].item(), \"float\") #item converts numpy.float to py float\n",
    "\n",
    "label_df = label_df.withColumn('features', toList(f.array('l_encoding', 'r_encoding', 'sim')))\n",
    "label_df = label_df.withColumn('simil', to_double(f.col('sim')))\n",
    "p = label_df.filter(\"label==1 AND simil>0.5\").count() / label_df.filter('simil>0.5').count()\n",
    "r = label_df.filter(\"label==1 AND simil>0.5\").count() / label_df.filter(f.col('label')==1).count()\n",
    "f1 = 2*p*r/(p+r)\n",
    "print(\"F1 score: \", f1)\n",
    "label_df = label_df.withColumn('label', f.col('label').cast(t.IntegerType()))\n",
    "\n",
    "matching_pairs = matching_pairs.\\\n",
    "    withColumn('simil', to_double('sim')).\\\n",
    "    filter('simil > 0.5').\\\n",
    "    drop('simil').\\\n",
    "    withColumn('features', toList(f.array('l_encoding', 'r_encoding', 'sim')))\\\n",
    "    .drop('l_encoding', 'r_encoding', 'sim')\n",
    "\n",
    "matching_pairs = matching_pairs.withColumnRenamed('src', 'lid').withColumnRenamed('dst','rid')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mla9wzTj6g62"
   },
   "source": [
    "# 3. Machine Learning Magic Bitch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YP1eg3sE6g62"
   },
   "source": [
    "from pyspark.ml.classification import LinearSVC, LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "scCBn8BJ6g63"
   },
   "source": [
    "#model = LinearSVC(featuresCol='features', labelCol='label', weightCol='weights',maxIter=100)\n",
    "model = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "param_grid = ParamGridBuilder().addGrid(model.regParam, [0.5, 0.4, 0.3, 0.2, 0.1]).build()\n",
    "cvs = CrossValidator(estimator=model,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),#(rawPredictionCol='prediction', labelCol='label'),\\\n",
    "                           numFolds=8)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "EjGJSEK46g63"
   },
   "source": [
    "#Set weights\n",
    "w = 0.04\n",
    "label_df = label_df.withColumn('weights', f.when(f.col('label')==0, w)\\\n",
    "                               .otherwise(1.0))\n",
    "training_set, test_set = label_df.randomSplit([0.8, 0.2])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3E_ceDGU6g63"
   },
   "source": [
    "#grid_search, hyperpar tuning...\n",
    "estimator = cvs.fit(training_set)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "G_EWxg696g63"
   },
   "source": [
    "prediction = estimator.transform(test_set).select('lid','rid','label','prediction')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "coxTEkuVeP8o",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "prediction.groupby(\"prediction\").count().toPandas()\n",
    "\n",
    "estimator.save(\"model.model\")\n",
    "!zip -r model.zip model.model\n",
    "\n",
    "accuracy = prediction.filter(f.col('label')==f.col('prediction').cast(t.IntegerType())).count() / prediction.count()\n",
    "print(\"Accuracy: \", accuracy)\n",
    "p = prediction.filter(\"label==1 AND prediction==1\").count() / prediction.filter('prediction==1').count()\n",
    "r = prediction.filter(\"label==1 AND prediction==1\").count() / prediction.filter('label == 1').count()\n",
    "f1 = 2*p*r/(p+r)\n",
    "print(\"F1 score: \", f1)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}