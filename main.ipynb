{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a2066b67",
   "language": "python",
   "display_name": "PyCharm (sigmod-2021)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "g6Wjqcnc6oEe"
   },
   "source": [
    "!pip install pyspark graphframes"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: graphframes in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (0.6)\r\n",
      "Requirement already satisfied: numpy in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from graphframes) (1.19.5)\r\n",
      "Requirement already satisfied: nose in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from graphframes) (1.3.7)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from pyspark) (0.10.9)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yB4SXU_m7w-Q"
   },
   "source": [
    "!export PYSPARK_SUBMIT_ARGS='--packages graphframes:graphframes:0.8.1-spark3.0-s_2.12'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "brY-5_-X6g6p"
   },
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import tensorflow_hub as hub\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql import Window as w\n",
    "from graphframes import GraphFrame\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer, CountVectorizer, StopWordsRemover, NGram, Normalizer, VectorAssembler, Word2Vec, Word2VecModel, PCA\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "UqZuRaaW6g6r"
   },
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .config('spark.executor.memory', '4g')\n",
    "    .config('spark.app.name', 'Spark Updated Conf')\n",
    "    .config('spark.executor.cores', '2')\n",
    "    .config('spark.cores.max', '2')\n",
    "    .config('spark.driver.memory','8g')\n",
    "    .getOrCreate()\n",
    ")"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "uB4VNsak6g6t"
   },
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "PaEElmjg6g6u"
   },
   "source": [
    "df = spark.read.csv(\"./data/X2.csv\", header=True)\n",
    "df.toPandas()"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                  instance_id  \\\n0    www.softwarecity.ca//737   \n1    www.isupplyhub.com//1256   \n2     www.isupplyhub.com//326   \n3     www.isupplyhub.com//821   \n4     www.isupplyhub.com//157   \n..                        ...   \n338       www.vology.com//873   \n339       www.vology.com//823   \n340      www.vology.com//2723   \n341      www.vology.com//1349   \n342      www.vology.com//3017   \n\n                                                 brand  \\\n0                                               Lenovo   \n1                                                 Acer   \n2                                                 Acer   \n3                                                   HP   \n4                                                 Asus   \n..                                                 ...   \n338  Lenovo ThinkPad X230 2320 - 12.5 '' - Core i5 ...   \n339  Lenovo ThinkPad X230 2325 - 12.5 '' - Core i5 ...   \n340  Lenovo ThinkPad X230 Tablet 3438 - 12.5 '' - C...   \n341  Lenovo ThinkPad X230 2324 - 12.5 '' - Core i5 ...   \n342  Lenovo ThinkPad X230 2320 - 12.5 '' - Core i7 ...   \n\n                                             cpu_brand  \\\n0                                      Intel. i5-3320M   \n1           1.6 GHz Intel Core i5-4200U. Intel Core I5   \n2                 1.6 GHz Intel Core i5. Intel Core I5   \n3                                                 None   \n4                         1.7 GHz Core i5-3317U. Intel   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                             cpu_model  \\\n0                                             i5-3320M   \n1                                                 None   \n2                                                 None   \n3                                                 None   \n4                                                 None   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                              cpu_type  \\\n0                        Dual-core ( 2 Core ). Core i5   \n1                          1.6 GHz Intel Core i5-4200U   \n2                                1.6 GHz Intel Core i5   \n3                                                 None   \n4                                1.7 GHz Core i5-3317U   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                         cpu_frequency  \\\n0                                             2.60 GHz   \n1                          1.6 GHz Intel Core i5-4200U   \n2                                1.6 GHz Intel Core i5   \n3                                                 None   \n4                                1.7 GHz Core i5-3317U   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                          ram_capacity  \\\n0                                                 None   \n1                                     8 GB DDR3L SDRAM   \n2                                      4 GB DDR3-SDRAM   \n3                                      4 GB SDRAM DDR3   \n4                                            4 GB DDR3   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                              ram_type  \\\n0          DDR3 SDRAM. DDR3-1600/PC3-12800. DDR3 SDRAM   \n1                         DDR3 SDRAM. 8 GB DDR3L SDRAM   \n2                          DDR3 SDRAM. 4 GB DDR3-SDRAM   \n3                          DDR3 SDRAM. 4 GB SDRAM DDR3   \n4                                DDR3 SDRAM. 4 GB DDR3   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                         ram_frequency  \\\n0                                  DDR3-1600/PC3-12800   \n1                                                 None   \n2                                                 None   \n3                                                 None   \n4                                                 None   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                          hdd_capacity  \\\n0                                               320 GB   \n1                         500 GB mechanical_hard_drive   \n2                         500 GB mechanical_hard_drive   \n3                                               500 GB   \n4                                               256 MB   \n..                                                 ...   \n338  180 GB SSD. 180 GB SSD. Lenovo ThinkPad X230 2...   \n339  500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...   \n340  500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...   \n341  320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm. ...   \n342  256 GB SSD - Self Encrypting Drive. 256 GB SSD...   \n\n                                          ssd_capacity           weight  \\\n0                                                 None          1.80 kg   \n1                                                 None       4.8 pounds   \n2                                                 None       5.2 pounds   \n3                                                 None       4.8 pounds   \n4                                                 None       2.9 pounds   \n..                                                 ...              ...   \n338                             180 GB SSD. 180 GB SSD  3.3 lbs 3.3 lbs   \n339       500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm  3.3 lbs 3.3 lbs   \n340       500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm      4 lbs 4 lbs   \n341       320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm  3.3 lbs 3.3 lbs   \n342  256 GB SSD - Self Encrypting Drive. 256 GB SSD...  3.3 lbs 3.3 lbs   \n\n                                     dimensions  \\\n0                                          None   \n1                   15.02 x 10.08 x 0.90 inches   \n2                      15.02 x 10.08 x 1 inches   \n3                   15.18 x 0.89 x 10.16 inches   \n4                    8.80 x 0.70 x 12.80 inches   \n..                                          ...   \n338  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n339  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n340  9 in. 12 in x 9 in x 1.2 in. 1.2 in. 12 in   \n341  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n342  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n\n                                                 title  \n0    \"Lenovo Thinkpad X230 34352jf Tablet Pc - 12.5...  \n1    Amazon.com : Acer Aspire V7-582PG-6479 15.6-In...  \n2    Amazon.com : Acer Aspire E1-572-6870 15.6 Inch...  \n3    \"Amazon.com : 15.6\"\" HP 15-f009wm Amd Dual-Cor...  \n4    Amazon.com : ASUS UX31A-XB52 13.3-Inch Ultrabo...  \n..                                                 ...  \n338  \"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i5 ...  \n339  \"Lenovo ThinkPad X230 2325 - 12.5\"\" - Core i5 ...  \n340  \"Lenovo ThinkPad X230 Tablet 3438 - 12.5\"\" - C...  \n341  \"Lenovo ThinkPad X230 2324 - 12.5\"\" - Core i5 ...  \n342  \"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i7 ...  \n\n[343 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instance_id</th>\n      <th>brand</th>\n      <th>cpu_brand</th>\n      <th>cpu_model</th>\n      <th>cpu_type</th>\n      <th>cpu_frequency</th>\n      <th>ram_capacity</th>\n      <th>ram_type</th>\n      <th>ram_frequency</th>\n      <th>hdd_capacity</th>\n      <th>ssd_capacity</th>\n      <th>weight</th>\n      <th>dimensions</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>www.softwarecity.ca//737</td>\n      <td>Lenovo</td>\n      <td>Intel. i5-3320M</td>\n      <td>i5-3320M</td>\n      <td>Dual-core ( 2 Core ). Core i5</td>\n      <td>2.60 GHz</td>\n      <td>None</td>\n      <td>DDR3 SDRAM. DDR3-1600/PC3-12800. DDR3 SDRAM</td>\n      <td>DDR3-1600/PC3-12800</td>\n      <td>320 GB</td>\n      <td>None</td>\n      <td>1.80 kg</td>\n      <td>None</td>\n      <td>\"Lenovo Thinkpad X230 34352jf Tablet Pc - 12.5...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>www.isupplyhub.com//1256</td>\n      <td>Acer</td>\n      <td>1.6 GHz Intel Core i5-4200U. Intel Core I5</td>\n      <td>None</td>\n      <td>1.6 GHz Intel Core i5-4200U</td>\n      <td>1.6 GHz Intel Core i5-4200U</td>\n      <td>8 GB DDR3L SDRAM</td>\n      <td>DDR3 SDRAM. 8 GB DDR3L SDRAM</td>\n      <td>None</td>\n      <td>500 GB mechanical_hard_drive</td>\n      <td>None</td>\n      <td>4.8 pounds</td>\n      <td>15.02 x 10.08 x 0.90 inches</td>\n      <td>Amazon.com : Acer Aspire V7-582PG-6479 15.6-In...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>www.isupplyhub.com//326</td>\n      <td>Acer</td>\n      <td>1.6 GHz Intel Core i5. Intel Core I5</td>\n      <td>None</td>\n      <td>1.6 GHz Intel Core i5</td>\n      <td>1.6 GHz Intel Core i5</td>\n      <td>4 GB DDR3-SDRAM</td>\n      <td>DDR3 SDRAM. 4 GB DDR3-SDRAM</td>\n      <td>None</td>\n      <td>500 GB mechanical_hard_drive</td>\n      <td>None</td>\n      <td>5.2 pounds</td>\n      <td>15.02 x 10.08 x 1 inches</td>\n      <td>Amazon.com : Acer Aspire E1-572-6870 15.6 Inch...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>www.isupplyhub.com//821</td>\n      <td>HP</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>4 GB SDRAM DDR3</td>\n      <td>DDR3 SDRAM. 4 GB SDRAM DDR3</td>\n      <td>None</td>\n      <td>500 GB</td>\n      <td>None</td>\n      <td>4.8 pounds</td>\n      <td>15.18 x 0.89 x 10.16 inches</td>\n      <td>\"Amazon.com : 15.6\"\" HP 15-f009wm Amd Dual-Cor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>www.isupplyhub.com//157</td>\n      <td>Asus</td>\n      <td>1.7 GHz Core i5-3317U. Intel</td>\n      <td>None</td>\n      <td>1.7 GHz Core i5-3317U</td>\n      <td>1.7 GHz Core i5-3317U</td>\n      <td>4 GB DDR3</td>\n      <td>DDR3 SDRAM. 4 GB DDR3</td>\n      <td>None</td>\n      <td>256 MB</td>\n      <td>None</td>\n      <td>2.9 pounds</td>\n      <td>8.80 x 0.70 x 12.80 inches</td>\n      <td>Amazon.com : ASUS UX31A-XB52 13.3-Inch Ultrabo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>www.vology.com//873</td>\n      <td>Lenovo ThinkPad X230 2320 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>180 GB SSD. 180 GB SSD. Lenovo ThinkPad X230 2...</td>\n      <td>180 GB SSD. 180 GB SSD</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>www.vology.com//823</td>\n      <td>Lenovo ThinkPad X230 2325 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2325 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>www.vology.com//2723</td>\n      <td>Lenovo ThinkPad X230 Tablet 3438 - 12.5 '' - C...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm</td>\n      <td>4 lbs 4 lbs</td>\n      <td>9 in. 12 in x 9 in x 1.2 in. 1.2 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 Tablet 3438 - 12.5\"\" - C...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>www.vology.com//1349</td>\n      <td>Lenovo ThinkPad X230 2324 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm. ...</td>\n      <td>320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2324 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>www.vology.com//3017</td>\n      <td>Lenovo ThinkPad X230 2320 - 12.5 '' - Core i7 ...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>256 GB SSD - Self Encrypting Drive. 256 GB SSD...</td>\n      <td>256 GB SSD - Self Encrypting Drive. 256 GB SSD...</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i7 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>343 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "nj-gVsHx6g6v"
   },
   "source": [
    "# 0. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Pasvnmhd6g6w"
   },
   "source": [
    "# Set everything to lowercase\n",
    "for c in df.columns:\n",
    "    df = df.withColumn(c, f.lower(f.col(c)))\n",
    "\n",
    "df = df.drop('ssd_capacity')\n",
    "df = df.drop('dimensions')\n",
    "# Extract brand or infer from title\n",
    "df = df.withColumn('brand', f.regexp_extract('brand', \"^(\\w+)\", 0))\n",
    "computer_brands = ['lenovo', 'acer', 'hp', 'dell', 'asus', 'samsung', 'huawei', 'surface', 'apple']\n",
    "computer_brands_pattern = '({})'.format('|'.join(computer_brands))\n",
    "df = df.withColumn('brand', f.when( f.regexp_extract('title', computer_brands_pattern, 0)!='', f.regexp_extract('title', computer_brands_pattern, 0))\\\n",
    "                   .otherwise(df.brand))\n",
    "#exctract cpu_brand and infer type if intel\n",
    "cpu_brands = ['intel', 'apple', 'amd', 'nvidia', 'arm']\n",
    "cpu_pattern = '({})'.format('|'.join(cpu_brands))\n",
    "df = df.withColumn('cpu_model',f.regexp_extract('cpu_model', '(i\\d|pentium|celeron|a\\d)', 0))\n",
    "df = df.withColumn('cpu_model', f.when( (f.regexp_extract('cpu_brand','(intel|amd)', 0 )!='') & f.isnull(df.cpu_model) ,\\\n",
    "                                        f.regexp_extract('cpu_brand', '(i\\d|pentium|celeron|a\\d)', 0))\\\n",
    "                   .otherwise(df.cpu_model))\n",
    "df = df.withColumn('cpu_brand', f.when(f.regexp_extract('cpu_brand', cpu_pattern, 0) != '', f.regexp_extract('cpu_brand', cpu_pattern, 1))\\\n",
    "                                       .otherwise(f.regexp_extract('title', cpu_pattern, 0)))\n",
    "#convert weight from pounds to kilos\n",
    "df = df.withColumn('weight', f.when(df.weight.contains('pounds') | df.weight.contains('lbs'),\n",
    "                                    (f.regexp_extract('weight', '(\\d+.?\\d)', 0).cast(t.DoubleType()))).otherwise(\n",
    "                                    f.round(f.regexp_extract('weight', '(\\d+.?\\d)', 0).cast(t.DoubleType())*2.20462,1)\n",
    "                        )\n",
    "                    )\n"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tNIZDK-K-EGd"
   },
   "source": [
    "#from more_itertools import intersperse\n",
    "\n",
    "def merge_columns(df, column_names, output):\n",
    "    df = df.withColumn(output, f.concat_ws(\" \", *column_names))\n",
    "    return df.drop(*column_names)\n",
    "\n",
    "ddf = df.drop(\"ram_frequency\")\n",
    "#merge ram columns and cpu columns into one for ram and one for cpu\n",
    "ddf = merge_columns(ddf, [\"cpu_brand\", \"cpu_model\", \"cpu_frequency\", \"cpu_type\"], \"cpu\")\n",
    "ddf = merge_columns(ddf, [\"ram_capacity\", \"ram_type\"], \"ram\")\n",
    "ddf.columns"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['instance_id', 'brand', 'hdd_capacity', 'weight', 'title', 'cpu', 'ram']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5lLUdrr6g6w"
   },
   "source": [
    "# 1. Blocking\n",
    "Blocking will be done feeding a TF-IDF matrix to an LDA model and extracting\n",
    "keywords from the title matching them to topics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "qEBkED7C6g6x"
   },
   "source": [
    "@f.udf(returnType=t.ArrayType(t.StringType()))\n",
    "def filter_alnum(arr):\n",
    "    return [t for t in arr if t.isalnum() and len(t) > 2]\n",
    "\n",
    "\"\"\"Returns the df with tokenized columns with stopwords removed\"\"\"\n",
    "def tokenize(df, string_cols):\n",
    "    output = df\n",
    "    stopW = ['softwarecity', 'amazon', 'com', 'pc', 'windows', 'computers', 'computer', 'accessories', 'laptop', 'notebook', 'kg', 'inch', 'processor', 'memory','gb', 'ram', 'hdd', 'ssd', 'cpu', 'display', 'hz', 'ghz', 'tb','rpm', 'slot', 'slots', 'mhz', 'cache', 'ram', 'ddram', 'dram', 'hd']\n",
    "    for c in string_cols:\n",
    "        output = output.withColumn('temp', f.coalesce(f.col(c), f.lower(c), f.lit('')))\n",
    "        tokenizer = RegexTokenizer(inputCol='temp', outputCol=c+\"_rawtokens\", pattern = \"\\\\W\")\n",
    "        remover = StopWordsRemover(inputCol=c+\"_rawtokens\", outputCol=c+\"_tokens\", stopWords=stopW)\n",
    "\n",
    "        output = tokenizer.transform(output)\n",
    "        output = remover.transform(output).drop(c+\"_rawtokens\")\n",
    "        output = output.withColumn(c+'_tokens', f.array_distinct(filter_alnum(f.col(c+\"_tokens\"))))\n",
    "    # output has c+tokens columns\n",
    "    return output.drop(\"temp\")\n",
    "\n",
    "def generate_blocking_keys(df, token_cols, min_freq=1):\n",
    "    \"\"\"Pipeline:\n",
    "            1 - CountVectorizer -> TF\n",
    "            2 - IDF\n",
    "            3 - LDA\n",
    "    \"\"\"\n",
    "    df = df.withColumn('tokens', f.array_distinct(f.concat(*token_cols)))\\\n",
    "        .drop('title_tokens')\\\n",
    "        .drop('cpu_tokens')\\\n",
    "        .drop('ram_tokens')\\\n",
    "        .drop('brand_tokens')\n",
    "    cv = CountVectorizer(inputCol='tokens', outputCol=\"raw_features\")\n",
    "    cvmodel = cv.fit(df)\n",
    "    df_vect = cvmodel.transform(df)\n",
    "\n",
    "    idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=min_freq)\n",
    "    idfModel = idf.fit(df_vect)\n",
    "    df_idf= idfModel.transform(df_vect)\n",
    "\n",
    "    normalizer = Normalizer(p=2.0, inputCol='features', outputCol='tfidf')\n",
    "    output = normalizer.transform(df_idf)\n",
    "    output = output.drop('raw_features').drop('features')\n",
    "    lda = LDA(k=5, maxIter=1000, featuresCol='tfidf')\n",
    "    lda_model = lda.fit(output)\n",
    "    vocab = cvmodel.vocabulary\n",
    "    #returns words for each topic term\n",
    "    @f.udf(returnType=t.ArrayType(t.StringType()))\n",
    "    def get_words(token_list):\n",
    "        return [vocab[token_id] for token_id in token_list]\n",
    "\n",
    "    #create list of topic keywords\n",
    "    # i.e topic 1 -> acer, anspire, intel\n",
    "    topics = lda_model.describeTopics(3).withColumn('topicWords', get_words(f.col('termIndices'))).collect()\n",
    "    list_of_topics = []\n",
    "    for r in topics:\n",
    "        topicW = r.__getitem__('topicWords')\n",
    "        for w in topicW:\n",
    "            list_of_topics.append(w)\n",
    "\n",
    "    #returns list of 3 'hashtags' i.e keywords for topic\n",
    "    #from tokens: title, brand, cpu_brand\n",
    "    @f.udf(returnType=t.ArrayType(t.StringType()))\n",
    "    def get_key(words):\n",
    "        l = [w for w in words if w in list_of_topics]\n",
    "        l = list(set(l))\n",
    "        l.sort()\n",
    "        return l[:3]\n",
    "    output = output.withColumn(\"blocking_key\", get_key(f.col(\"tokens\")))\n",
    "    return output\n",
    "\n",
    "\"\"\"Use universal sentence encoder from tensorflow_hub\"\"\"\n",
    "MODEL = None\n",
    "def get_model_magic():\n",
    "  global MODEL\n",
    "  if MODEL is None:\n",
    "      MODEL = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "  return MODEL\n",
    "\n",
    "@f.udf(returnType=VectorUDT())\n",
    "def encode_sentence(x):\n",
    "  model = get_model_magic()\n",
    "  emb = model([x]).numpy()[0]\n",
    "  return Vectors.dense(emb)"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ouaaVLVQ6g6y"
   },
   "source": [
    "columns = ['title', 'brand', 'cpu', 'ram']\n",
    "#Generate Blocking Keys\n",
    "\n",
    "blocking_df = tokenize(ddf, columns)\n",
    "blocking_df = generate_blocking_keys(blocking_df, [c+'_tokens' for c in columns])\n",
    "blocking_df.limit(1).show()"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|         instance_id| brand|hdd_capacity|weight|               title|                 cpu|                 ram|brand_tokens|              tokens|               tfidf|        blocking_key|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "|www.softwarecity....|lenovo|      320 gb|   4.0|\"lenovo thinkpad ...|intel i5 2.60 ghz...|ddr3 sdram. ddr3-...|    [lenovo]|[lenovo, thinkpad...|(350,[0,1,2,3,6,7...|[12800, 3320m, co...|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         instance_id| brand|hdd_capacity|weight|               title|                 cpu|                 ram|brand_tokens|              tokens|               tfidf|        blocking_key|           to_encode|            encoding|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|www.softwarecity....|lenovo|      320 gb|   4.0|\"lenovo thinkpad ...|intel i5 2.60 ghz...|ddr3 sdram. ddr3-...|    [lenovo]|[lenovo, thinkpad...|(350,[0,1,2,3,6,7...|[12800, 3320m, co...|\"lenovo thinkpad ...|[0.02892581000924...|\n",
      "+--------------------+------+------------+------+--------------------+--------------------+--------------------+------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Add encoding\n",
    "cols_to_encode = columns\n",
    "cols_to_encode.append('hdd_capacity')\n",
    "cols_to_encode.append('weight')\n",
    "blocking_df = blocking_df.withColumn('to_encode', f.concat(*cols_to_encode))\n",
    "blocking_df = blocking_df.withColumn('encoding', encode_sentence(f.coalesce(f.col('to_encode'), f.lit(''))))\n",
    "\n",
    "blocking_df.limit(1).show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "AfgQ2rjy6g6z"
   },
   "source": [
    "blocking_df.groupby('blocking_key').count().show()"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        blocking_key|count|\n",
      "+--------------------+-----+\n",
      "|[12800, 3320m, co...|    1|\n",
      "|  [4005u, 571, acer]|    1|\n",
      "|      [12800, 3320m]|    3|\n",
      "|[acer, aspire, pr...|   21|\n",
      "|                  []|   57|\n",
      "|[12800, 3320m, x230]|  104|\n",
      "|   [011, 4005u, 571]|    1|\n",
      "|      [acer, aspire]|   31|\n",
      "|             [12800]|    6|\n",
      "|       [convertible]|    4|\n",
      "|       [12800, x230]|   26|\n",
      "|[integrated, prov...|   71|\n",
      "|       [3320m, x230]|    4|\n",
      "| [571, acer, aspire]|    7|\n",
      "|              [x230]|    1|\n",
      "|           [premium]|    3|\n",
      "|[12800, 3320m, mu...|    1|\n",
      "|[3320m, convertib...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "ewM2XlPt6g60"
   },
   "source": [
    "# 2. Candidate pairs generation and match likelihood"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "g_FB3bXg6g60"
   },
   "source": [
    "\"\"\"\n",
    "This cell output a candidates dataframe that has\n",
    "instance_ids pairs that makes sense to compare, i.e each\n",
    "entity will be paired with another entity from the same block\n",
    "\"\"\"\n",
    "\n",
    "cols_to_keep = [\"instance_id\", \"encoding\"]\n",
    "# Filter blocks to only keep ones bigger than one\n",
    "pairs = (\n",
    "    blocking_df\n",
    "    .select(*cols_to_keep, 'blocking_key')\n",
    "    .groupby('blocking_key').agg(f.count('instance_id').alias('size'), f.collect_set('instance_id').alias('id'))\\\n",
    "    .filter(f.col('size') > 1).select('blocking_key',f.explode('id').alias('id'))\n",
    ")\n",
    "\n",
    "left = pairs.withColumnRenamed('id', 'src')\n",
    "right = pairs.withColumnRenamed('id', 'dst')\n",
    "#candidates based on matching of blocking_key (i.e inside the block)\n",
    "candidates = left.join(right, ['blocking_key'], 'inner')\\\n",
    "    .filter(f.col('src') < f.col('dst'))\\\n",
    "    .select('src', 'dst').distinct()\n",
    "node = blocking_df.select(f.col('instance_id').alias('id'), 'encoding').drop('instance_id')"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1rMiiAQC6g60"
   },
   "source": [
    "\"\"\"\n",
    "@f.udf(returnType=t.DoubleType())\n",
    "def dot(x, y):\n",
    "  if x is not None and y is not None:\n",
    "    return float(x.dot(y))\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def null_safe_levenshtein_sim(c1, c2):\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .otherwise(1 - f.levenshtein(c1, c2) / f.greatest(f.length(c1), f.length(c2)))\n",
    "  return output\n",
    "\n",
    "def null_safe_num_sim(c1, c2):\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .when((f.col(c1) == 0) & (f.col(c2) == 0), 1)\\\n",
    "            .when((f.col(c1) == 0) | (f.col(c2) == 0), 0)\\\n",
    "            .otherwise(1 - f.abs(f.col(c1) - f.col(c2)) / f.greatest(c1, c2))\n",
    "  return output\n",
    "\n",
    "def null_safe_token_overlap(c1, c2):\n",
    "  # is the overlap a significant part of the shorter string\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .when((f.size(f.array_distinct(c1)) == 0) | (f.size(f.array_distinct(c2)) == 0), 0)\\\n",
    "            .otherwise(f.size(f.array_intersect(c1, c2)) / f.least(f.size(f.array_distinct(c1)), f.size(f.array_distinct(c1))))\n",
    "  return output\n",
    "\n",
    "def calc_sim(df, candidates):\n",
    "    metrics = []\n",
    "    for c in columns[:2]:\n",
    "        if '_encoding' not in c:\n",
    "            candidates = candidates.withColumn(c+'_lev', null_safe_levenshtein_sim(df.filter(df.id == candidates.src).select(c),df.filter(df.id == candidates.dst).select(c)))\n",
    "            metrics.append(c+'_lev')\n",
    "        else:\n",
    "            metrics.append(c+'_sim')\n",
    "            candidates = candidates.withColumn(c+'_sim', dot(df.filter(df.id == candidates.src).select(c), df.filter(df.id == candidates.dst).select(c)))\n",
    "    candidates = candidates.withColumn('tfidf_sim', dot(df.filter(df.id == candidates.src).select('tfidf'),df.filter(df.id == candidates.dst).select('tfidf')))\n",
    "    candidates = candidates.withColumn('token_sim', dot(df.filter(df.id == candidates.src).select('tokens_swRemoved'), df.filter(df.id == candidates.dst).select('tokens_swRemoved')))\n",
    "    candidates = candidates.withColumn('weight_sim', dot(df.filter(df.id == candidates.src).select('weight'),df.filter(df.id == candidates.dst).select('weight')))\n",
    "    metrics.append('tfidf_sim')\n",
    "    metrics.append('token_sim')\n",
    "    metrics.append('weigth_sim')\n",
    "    def sum_distance(distances):\n",
    "        return sum(d for d in distances)\n",
    "    udf_sum = f.udf(sum_distance, t.DoubleType())\n",
    "    candidates = candidates.withColumn('sum_sim', udf_sum([f.col(c) for c in metrics]))\n",
    "    udf_norm = f.udf(lambda d : d / len(metrics))\n",
    "    candidates = candidates.withColumn('overall_sim', udf_norm(f.col('sum_sim'))).drop(f.col('sum_sim'))\n",
    "    return candidates\n",
    "\n",
    "distance_df = calc_sim(node, candidates)\n",
    "\"\"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dLFCsO_D6g61"
   },
   "source": [
    "\"\"\"\n",
    "Read label.csv and expand it trough transitivity\n",
    "\"\"\"\n",
    "labels = (\n",
    "    spark.read.csv(\"./data/Y2.csv\", header=True)\n",
    "    .withColumnRenamed('left_instance_id', 'lid')\n",
    "    .withColumnRenamed('right_instance_id', 'rid')\n",
    ")"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "LV2XM0oB6g62"
   },
   "source": [
    "\"\"\"\n",
    "Reuse this cell to join a <left_id,right_id> with node to extract features\n",
    "\"\"\"\n",
    "#label_df = labels.join(candidates.withColumnRenamed('src','lid').withColumnRenamed('dst','rid'), ['lid','rid'], 'inner')\n",
    "label_df = labels.join(node.alias(\"node_1\"), labels.lid == node.id, 'inner').drop('id')\n",
    "for c in cols_to_keep[1:]:\n",
    "    label_df = label_df.withColumnRenamed(c, 'l_'+c)\n",
    "\n",
    "label_df = label_df.alias('one').join(node.alias(\"node_2\"), label_df.rid == node.id, 'inner').drop('id')\n",
    "for c in cols_to_keep[1:]:\n",
    "    label_df = label_df.withColumnRenamed(c, 'r_'+c)\n",
    "print(label_df.columns)\n",
    "\n",
    "matching_pairs = candidates.join(node.alias(\"node_1\"), candidates.src == node.id, 'inner').drop('id')\n",
    "for c in cols_to_keep[1:]:\n",
    "    matching_pairs = matching_pairs.withColumnRenamed(c, 'l_'+c)\n",
    "\n",
    "matching_pairs = matching_pairs.alias('one').join(node.alias(\"node_2\"), matching_pairs.dst == node.id, 'inner').drop('id')\n",
    "for c in cols_to_keep[1:]:\n",
    "    matching_pairs = matching_pairs.withColumnRenamed(c, 'r_'+c)\n",
    "\n",
    "matching_pairs.columns"
   ],
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lid', 'rid', 'label', 'l_encoding', 'r_encoding']\n"
     ]
    },
    {
     "data": {
      "text/plain": "['src', 'dst', 'l_encoding', 'r_encoding']"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "trF-IsGj6g62"
   },
   "source": [
    "@f.udf(returnType=VectorUDT())\n",
    "def toList(row):\n",
    "    l = []\n",
    "    for v in row:\n",
    "        for n in v:\n",
    "            l.append(float(n))\n",
    "    return Vectors.dense(l)\n",
    "\n",
    "label_df = label_df.withColumn('features', toList(f.array('l_encoding', 'r_encoding')))\\\n",
    "    .drop('l_encoding', 'r_encoding')\n",
    "label_df = label_df.withColumn('label', f.col('label').cast(t.IntegerType()))\n",
    "\n",
    "\n",
    "matching_pairs = matching_pairs.\\\n",
    "    withColumn('features', toList(f.array('l_encoding', 'r_encoding')))\\\n",
    "    .drop('l_encoding', 'r_encoding')\n",
    "\n",
    "matching_pairs = matching_pairs.withColumnRenamed('src', 'lid').withColumnRenamed('dst','rid')"
   ],
   "execution_count": 85,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mla9wzTj6g62"
   },
   "source": [
    "# 3. Machine Learning Magic Bitch"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YP1eg3sE6g62"
   },
   "source": [
    "from pyspark.ml.classification import LinearSVC, LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "scCBn8BJ6g63"
   },
   "source": [
    "model = LinearSVC(featuresCol='features', labelCol='label', weightCol='weights',maxIter=100)\n",
    "param_grid = ParamGridBuilder().addGrid(model.regParam, [0.5, 0.4, 0.3, 0.2, 0.1]).build()\n",
    "cvs = CrossValidator(estimator=model,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),#(rawPredictionCol='prediction', labelCol='label'),\\\n",
    "                           numFolds=4)"
   ],
   "execution_count": 86,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "EjGJSEK46g63"
   },
   "source": [
    "#Set weights\n",
    "label_df = label_df.withColumn('weights', f.when(f.col('label')==0, 0.05).otherwise(1.0))\n",
    "training_set, test_set = label_df.randomSplit([0.8, 0.2])"
   ],
   "execution_count": 87,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3E_ceDGU6g63"
   },
   "source": [
    "#grid_search, hyperpar tuning...\n",
    "estimator = cvs.fit(training_set)"
   ],
   "execution_count": 88,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "G_EWxg696g63"
   },
   "source": [
    "prediction = estimator.transform(test_set).select('lid','rid','label','prediction')"
   ],
   "execution_count": 89,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "coxTEkuVeP8o"
   },
   "source": [
    "prediction.groupby(\"prediction\").count().toPandas()"
   ],
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "   prediction  count\n0         0.0  11635\n1         1.0    119",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prediction</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>11635</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>119</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "faNzcXmMfD9t"
   },
   "source": [
    "estimator.save(\"model.model\")"
   ],
   "execution_count": 91,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fWwCDyjZfN4L"
   },
   "source": [
    "!zip -r model.zip model.model"
   ],
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: model.model/ (stored 0%)\r\n",
      "updating: model.model/bestModel/ (stored 0%)\r\n",
      "updating: model.model/bestModel/data/ (stored 0%)\r\n",
      "updating: model.model/bestModel/data/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model.model/bestModel/data/_SUCCESS (stored 0%)\r\n",
      "updating: model.model/bestModel/metadata/ (stored 0%)\r\n",
      "updating: model.model/bestModel/metadata/.part-00000.crc (stored 0%)\r\n",
      "updating: model.model/bestModel/metadata/part-00000 (deflated 45%)\r\n",
      "updating: model.model/bestModel/metadata/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model.model/bestModel/metadata/_SUCCESS (stored 0%)\r\n",
      "updating: model.model/estimator/ (stored 0%)\r\n",
      "updating: model.model/estimator/metadata/ (stored 0%)\r\n",
      "updating: model.model/estimator/metadata/.part-00000.crc (stored 0%)\r\n",
      "updating: model.model/estimator/metadata/part-00000 (deflated 45%)\r\n",
      "updating: model.model/estimator/metadata/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model.model/estimator/metadata/_SUCCESS (stored 0%)\r\n",
      "updating: model.model/evaluator/ (stored 0%)\r\n",
      "updating: model.model/evaluator/metadata/ (stored 0%)\r\n",
      "updating: model.model/evaluator/metadata/.part-00000.crc (stored 0%)\r\n",
      "updating: model.model/evaluator/metadata/part-00000 (deflated 33%)\r\n",
      "updating: model.model/evaluator/metadata/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model.model/evaluator/metadata/_SUCCESS (stored 0%)\r\n",
      "updating: model.model/metadata/ (stored 0%)\r\n",
      "updating: model.model/metadata/.part-00000.crc (stored 0%)\r\n",
      "updating: model.model/metadata/part-00000 (deflated 59%)\r\n",
      "updating: model.model/metadata/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model.model/metadata/_SUCCESS (stored 0%)\r\n",
      "  adding: model.model/bestModel/data/.part-00000-9d154e8a-7dcd-4864-bde3-67ff04f31c28-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model.model/bestModel/data/part-00000-9d154e8a-7dcd-4864-bde3-67ff04f31c28-c000.snappy.parquet (deflated 12%)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MCF1dofN6g64"
   },
   "source": [
    "accuracy = prediction.filter(f.col('label')==f.col('prediction').cast(t.IntegerType())).count() / prediction.count()\n",
    "print(\"Accuracy: \", accuracy)\n",
    "p = prediction.filter(\"label==1 AND prediction==1\").count() / prediction.filter('prediction==1').count()\n",
    "r = prediction.filter(\"label==1 AND prediction==1\").count() / prediction.filter(f.col('label')==1).count()\n",
    "f1 = 2*p*r/(p+r)\n",
    "print(\"F1 score: \", f1)"
   ],
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9611196188531563\n",
      "F1 score:  0.13282732447817838\n"
     ]
    }
   ]
  }
 ]
}