{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "import tensorflow_hub as hub\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql import types as t\n",
    "from pyspark.sql import Window as w\n",
    "from graphframes import GraphFrame\n",
    "from pyspark.ml.linalg import DenseVector, SparseVector\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, RegexTokenizer, CountVectorizer, StopWordsRemover, NGram, Normalizer, VectorAssembler, Word2Vec, Word2VecModel, PCA\n",
    "\n",
    "from pyspark.ml.clustering import LDA\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "\n",
    "conf = (SparkConf().setMaster('local').setAppName('sigmod-21').set('spark.executor.memory', '2G').set('spark.driver.memory', '4G')\\\n",
    "        .set('spark.sql.broadcastTimeout', '1000'))\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                  instance_id  \\\n0    www.softwarecity.ca//737   \n1    www.isupplyhub.com//1256   \n2     www.isupplyhub.com//326   \n3     www.isupplyhub.com//821   \n4     www.isupplyhub.com//157   \n..                        ...   \n338       www.vology.com//873   \n339       www.vology.com//823   \n340      www.vology.com//2723   \n341      www.vology.com//1349   \n342      www.vology.com//3017   \n\n                                                 brand  \\\n0                                               Lenovo   \n1                                                 Acer   \n2                                                 Acer   \n3                                                   HP   \n4                                                 Asus   \n..                                                 ...   \n338  Lenovo ThinkPad X230 2320 - 12.5 '' - Core i5 ...   \n339  Lenovo ThinkPad X230 2325 - 12.5 '' - Core i5 ...   \n340  Lenovo ThinkPad X230 Tablet 3438 - 12.5 '' - C...   \n341  Lenovo ThinkPad X230 2324 - 12.5 '' - Core i5 ...   \n342  Lenovo ThinkPad X230 2320 - 12.5 '' - Core i7 ...   \n\n                                             cpu_brand  \\\n0                                      Intel. i5-3320M   \n1           1.6 GHz Intel Core i5-4200U. Intel Core I5   \n2                 1.6 GHz Intel Core i5. Intel Core I5   \n3                                                 None   \n4                         1.7 GHz Core i5-3317U. Intel   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                             cpu_model  \\\n0                                             i5-3320M   \n1                                                 None   \n2                                                 None   \n3                                                 None   \n4                                                 None   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                              cpu_type  \\\n0                        Dual-core ( 2 Core ). Core i5   \n1                          1.6 GHz Intel Core i5-4200U   \n2                                1.6 GHz Intel Core i5   \n3                                                 None   \n4                                1.7 GHz Core i5-3317U   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                         cpu_frequency  \\\n0                                             2.60 GHz   \n1                          1.6 GHz Intel Core i5-4200U   \n2                                1.6 GHz Intel Core i5   \n3                                                 None   \n4                                1.7 GHz Core i5-3317U   \n..                                                 ...   \n338  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n339  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n340  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n341  Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...   \n342  Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...   \n\n                                          ram_capacity  \\\n0                                                 None   \n1                                     8 GB DDR3L SDRAM   \n2                                      4 GB DDR3-SDRAM   \n3                                      4 GB SDRAM DDR3   \n4                                            4 GB DDR3   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                              ram_type  \\\n0          DDR3 SDRAM. DDR3-1600/PC3-12800. DDR3 SDRAM   \n1                         DDR3 SDRAM. 8 GB DDR3L SDRAM   \n2                          DDR3 SDRAM. 4 GB DDR3-SDRAM   \n3                          DDR3 SDRAM. 4 GB SDRAM DDR3   \n4                                DDR3 SDRAM. 4 GB DDR3   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                         ram_frequency  \\\n0                                  DDR3-1600/PC3-12800   \n1                                                 None   \n2                                                 None   \n3                                                 None   \n4                                                 None   \n..                                                 ...   \n338  4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...   \n339  4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...   \n340  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n341  Form Factor SO DIMM 204-pin Technology DDR3 SD...   \n342  Empty Slots 1 Slots Qty 2 Max RAM Supported 16...   \n\n                                          hdd_capacity  \\\n0                                               320 GB   \n1                         500 GB mechanical_hard_drive   \n2                         500 GB mechanical_hard_drive   \n3                                               500 GB   \n4                                               256 MB   \n..                                                 ...   \n338  180 GB SSD. 180 GB SSD. Lenovo ThinkPad X230 2...   \n339  500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...   \n340  500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...   \n341  320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm. ...   \n342  256 GB SSD - Self Encrypting Drive. 256 GB SSD...   \n\n                                          ssd_capacity           weight  \\\n0                                                 None          1.80 kg   \n1                                                 None       4.8 pounds   \n2                                                 None       5.2 pounds   \n3                                                 None       4.8 pounds   \n4                                                 None       2.9 pounds   \n..                                                 ...              ...   \n338                             180 GB SSD. 180 GB SSD  3.3 lbs 3.3 lbs   \n339       500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm  3.3 lbs 3.3 lbs   \n340       500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm      4 lbs 4 lbs   \n341       320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm  3.3 lbs 3.3 lbs   \n342  256 GB SSD - Self Encrypting Drive. 256 GB SSD...  3.3 lbs 3.3 lbs   \n\n                                     dimensions  \\\n0                                          None   \n1                   15.02 x 10.08 x 0.90 inches   \n2                      15.02 x 10.08 x 1 inches   \n3                   15.18 x 0.89 x 10.16 inches   \n4                    8.80 x 0.70 x 12.80 inches   \n..                                          ...   \n338  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n339  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n340  9 in. 12 in x 9 in x 1.2 in. 1.2 in. 12 in   \n341  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n342  8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in   \n\n                                                 title  \n0    \"Lenovo Thinkpad X230 34352jf Tablet Pc - 12.5...  \n1    Amazon.com : Acer Aspire V7-582PG-6479 15.6-In...  \n2    Amazon.com : Acer Aspire E1-572-6870 15.6 Inch...  \n3    \"Amazon.com : 15.6\"\" HP 15-f009wm Amd Dual-Cor...  \n4    Amazon.com : ASUS UX31A-XB52 13.3-Inch Ultrabo...  \n..                                                 ...  \n338  \"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i5 ...  \n339  \"Lenovo ThinkPad X230 2325 - 12.5\"\" - Core i5 ...  \n340  \"Lenovo ThinkPad X230 Tablet 3438 - 12.5\"\" - C...  \n341  \"Lenovo ThinkPad X230 2324 - 12.5\"\" - Core i5 ...  \n342  \"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i7 ...  \n\n[343 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instance_id</th>\n      <th>brand</th>\n      <th>cpu_brand</th>\n      <th>cpu_model</th>\n      <th>cpu_type</th>\n      <th>cpu_frequency</th>\n      <th>ram_capacity</th>\n      <th>ram_type</th>\n      <th>ram_frequency</th>\n      <th>hdd_capacity</th>\n      <th>ssd_capacity</th>\n      <th>weight</th>\n      <th>dimensions</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>www.softwarecity.ca//737</td>\n      <td>Lenovo</td>\n      <td>Intel. i5-3320M</td>\n      <td>i5-3320M</td>\n      <td>Dual-core ( 2 Core ). Core i5</td>\n      <td>2.60 GHz</td>\n      <td>None</td>\n      <td>DDR3 SDRAM. DDR3-1600/PC3-12800. DDR3 SDRAM</td>\n      <td>DDR3-1600/PC3-12800</td>\n      <td>320 GB</td>\n      <td>None</td>\n      <td>1.80 kg</td>\n      <td>None</td>\n      <td>\"Lenovo Thinkpad X230 34352jf Tablet Pc - 12.5...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>www.isupplyhub.com//1256</td>\n      <td>Acer</td>\n      <td>1.6 GHz Intel Core i5-4200U. Intel Core I5</td>\n      <td>None</td>\n      <td>1.6 GHz Intel Core i5-4200U</td>\n      <td>1.6 GHz Intel Core i5-4200U</td>\n      <td>8 GB DDR3L SDRAM</td>\n      <td>DDR3 SDRAM. 8 GB DDR3L SDRAM</td>\n      <td>None</td>\n      <td>500 GB mechanical_hard_drive</td>\n      <td>None</td>\n      <td>4.8 pounds</td>\n      <td>15.02 x 10.08 x 0.90 inches</td>\n      <td>Amazon.com : Acer Aspire V7-582PG-6479 15.6-In...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>www.isupplyhub.com//326</td>\n      <td>Acer</td>\n      <td>1.6 GHz Intel Core i5. Intel Core I5</td>\n      <td>None</td>\n      <td>1.6 GHz Intel Core i5</td>\n      <td>1.6 GHz Intel Core i5</td>\n      <td>4 GB DDR3-SDRAM</td>\n      <td>DDR3 SDRAM. 4 GB DDR3-SDRAM</td>\n      <td>None</td>\n      <td>500 GB mechanical_hard_drive</td>\n      <td>None</td>\n      <td>5.2 pounds</td>\n      <td>15.02 x 10.08 x 1 inches</td>\n      <td>Amazon.com : Acer Aspire E1-572-6870 15.6 Inch...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>www.isupplyhub.com//821</td>\n      <td>HP</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>4 GB SDRAM DDR3</td>\n      <td>DDR3 SDRAM. 4 GB SDRAM DDR3</td>\n      <td>None</td>\n      <td>500 GB</td>\n      <td>None</td>\n      <td>4.8 pounds</td>\n      <td>15.18 x 0.89 x 10.16 inches</td>\n      <td>\"Amazon.com : 15.6\"\" HP 15-f009wm Amd Dual-Cor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>www.isupplyhub.com//157</td>\n      <td>Asus</td>\n      <td>1.7 GHz Core i5-3317U. Intel</td>\n      <td>None</td>\n      <td>1.7 GHz Core i5-3317U</td>\n      <td>1.7 GHz Core i5-3317U</td>\n      <td>4 GB DDR3</td>\n      <td>DDR3 SDRAM. 4 GB DDR3</td>\n      <td>None</td>\n      <td>256 MB</td>\n      <td>None</td>\n      <td>2.9 pounds</td>\n      <td>8.80 x 0.70 x 12.80 inches</td>\n      <td>Amazon.com : ASUS UX31A-XB52 13.3-Inch Ultrabo...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>338</th>\n      <td>www.vology.com//873</td>\n      <td>Lenovo ThinkPad X230 2320 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>4 GB DDR3 Slots Qty 2 Empty Slots 1 Max RAM Su...</td>\n      <td>180 GB SSD. 180 GB SSD. Lenovo ThinkPad X230 2...</td>\n      <td>180 GB SSD. 180 GB SSD</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>www.vology.com//823</td>\n      <td>Lenovo ThinkPad X230 2325 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>4 GB DDR3 Slots Qty 2 Max RAM Supported 16 GB ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2325 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>www.vology.com//2723</td>\n      <td>Lenovo ThinkPad X230 Tablet 3438 - 12.5 '' - C...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm. ...</td>\n      <td>500 GB HDD / 7200 rpm. 500 GB HDD / 7200 rpm</td>\n      <td>4 lbs 4 lbs</td>\n      <td>9 in. 12 in x 9 in x 1.2 in. 1.2 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 Tablet 3438 - 12.5\"\" - C...</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>www.vology.com//1349</td>\n      <td>Lenovo ThinkPad X230 2324 - 12.5 '' - Core i5 ...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Intel Core i5 ( 3rd Gen ) 3320M / 2.6 GHz. Int...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>Form Factor SO DIMM 204-pin Technology DDR3 SD...</td>\n      <td>320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm. ...</td>\n      <td>320 GB HDD / 7200 rpm. 320 GB HDD / 7200 rpm</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2324 - 12.5\"\" - Core i5 ...</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>www.vology.com//3017</td>\n      <td>Lenovo ThinkPad X230 2320 - 12.5 '' - Core i7 ...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Intel Core i7 ( 3rd Gen ) 3520M / 2.9 GHz. Int...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>Empty Slots 1 Slots Qty 2 Max RAM Supported 16...</td>\n      <td>256 GB SSD - Self Encrypting Drive. 256 GB SSD...</td>\n      <td>256 GB SSD - Self Encrypting Drive. 256 GB SSD...</td>\n      <td>3.3 lbs 3.3 lbs</td>\n      <td>8.1 in. 12 in x 8.1 in x 1 in. 1 in. 12 in</td>\n      <td>\"Lenovo ThinkPad X230 2320 - 12.5\"\" - Core i7 ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>343 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/X2.csv\", header=True)\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 0. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for c in df.columns:\n",
    "#set everything to lowercase\n",
    "    df = df.withColumn(c, f.lower(f.col(c)))\n",
    "\n",
    "#extract brand or infer from title\n",
    "df = df.drop('ssd_capacity')\n",
    "df = df.withColumn('brand', f.regexp_extract('brand', \"^(\\w+)\", 0))\n",
    "computer_brands = ['(lenovo', 'acer', 'hp', 'dell', 'asus', 'samsung', 'huawei', 'surface', 'apple)']\n",
    "computer_brands_pattern = '|'.join(computer_brands)\n",
    "df = df.withColumn('brand', f.when( f.regexp_extract('title', computer_brands_pattern, 0)!='', f.regexp_extract('title', computer_brands_pattern, 0))\\\n",
    "                   .otherwise(df.brand))\n",
    "#exctract cpu_brand and infer type if intel\n",
    "cpu_brands = ['(intel', 'apple', 'amd', 'nvidia', 'arm)']\n",
    "cpu_pattern = '|'.join(cpu_brands)\n",
    "df = df.withColumn('cpu_model',f.regexp_extract('cpu_model', '(i\\d|pentium|celeron|a\\d)', 0))\n",
    "df = df.withColumn('cpu_model', f.when( (f.regexp_extract('cpu_brand','(intel|amd)', 0 )!='') & f.isnull(df.cpu_model) ,\\\n",
    "                                        f.regexp_extract('cpu_brand', '(i\\d|pentium|celeron|a\\d)', 0))\\\n",
    "                   .otherwise(df.cpu_model))\n",
    "df = df.withColumn('cpu_brand', f.when(f.regexp_extract('cpu_brand', cpu_pattern, 0) != '', f.regexp_extract('cpu_brand', cpu_pattern, 1))\\\n",
    "                                       .otherwise(f.regexp_extract('title', cpu_pattern, 0)))\n",
    "df = df.withColumn('weight', f.when(df.weight.contains('pounds') | df.weight.contains('lbs'),\n",
    "                                    (f.regexp_extract('weight', '(\\d+.?\\d)', 0).cast(t.DoubleType()))).otherwise(\n",
    "                                    f.round(f.regexp_extract('weight', '(\\d+.?\\d)', 0).cast(t.DoubleType())*2.20462,1)\n",
    "                        )\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Blocking\n",
    "Blocking will be done feeding a TF-IDF matrix to an LDA model and extracting\n",
    "keywords from the title matching them to topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"UTILITIES\"\"\"\n",
    "\n",
    "\"\"\"Returns the df with tokenized columns with stopwords removed\"\"\"\n",
    "def tokenize(df, string_cols):\n",
    "  output = df\n",
    "  stopW = ['softwarecity', 'amazon', 'com','pc', 'windows', 'computers', 'computer', 'accessories', 'laptop', 'notebook', 'kg', 'inch', 'processor', 'memory','gb', 'ram', 'hdd', 'ssd', 'cpu', 'display', 'hz', 'ghz', 'tb','rpm', 'slot', 'slots', 'mhz', 'cache', 'ram', 'ddram', 'dram', 'hd']\n",
    "  for c in string_cols:\n",
    "    output = output.withColumn('temp', f.coalesce(f.col(c), f.lower(c), f.lit('')))\n",
    "    tokenizer = RegexTokenizer(inputCol='temp', outputCol=c+\"_tokens\", pattern = \"\\\\W\")\n",
    "    remover = StopWordsRemover(inputCol=c+\"_tokens\", outputCol=c+\"_swRemoved\", stopWords=stopW)\n",
    "    output = tokenizer.transform(output)\n",
    "\n",
    "    filter_alnum = f.udf(lambda l : [t for t in l if t.isalpha() and len(t) >= 2], t.ArrayType(t.StringType()))\n",
    "    output = output.withColumn(c+'_tokens', filter_alnum(f.col(c+\"_tokens\")))\n",
    "\n",
    "    output = remover.transform(output)\\\n",
    "      .drop('temp', c+\"_tokens\")\n",
    "    # output has c+swRemoved columns\n",
    "  return output\n",
    "\n",
    "def generate_blocking_keys(df, token_cols, min_freq=1):\n",
    "    \"\"\"Pipeline:\n",
    "            1 - CountVectorizer -> TF\n",
    "            2 - IDF\n",
    "            3 - LDA\n",
    "    \"\"\"\n",
    "    df = df.withColumn('tokens_swRemoved', f.concat(*token_cols))\n",
    "    cv = CountVectorizer(inputCol='tokens_swRemoved', outputCol=\"rawFeatures\")\n",
    "    cvmodel = cv.fit(df)\n",
    "    df_vect = cvmodel.transform(df)\n",
    "\n",
    "    idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=min_freq)\n",
    "    idfModel = idf.fit(df_vect)\n",
    "    df_idf= idfModel.transform(df_vect)\n",
    "\n",
    "    normalizer = Normalizer(p=2.0, inputCol='features', outputCol='tfidf')\n",
    "    output = normalizer.transform(df_idf)\n",
    "\n",
    "    lda = LDA(k=5, maxIter=1000, featuresCol='tfidf')\n",
    "    lda_model = lda.fit(output)\n",
    "    vocab = cvmodel.vocabulary\n",
    "    #returns words for each topic term\n",
    "    def get_words(token_list):\n",
    "        return [vocab[token_id] for token_id in token_list]\n",
    "\n",
    "    udf_to_words = f.udf(get_words, t.ArrayType(t.StringType()))\n",
    "\n",
    "    #create list of topic keywords\n",
    "    # i.e topic 1 -> acer, anspire, intel\n",
    "    topics = lda_model.describeTopics(3).withColumn('topicWords', udf_to_words(f.col('termIndices'))).collect()\n",
    "    list_of_topics = []\n",
    "    for r in topics:\n",
    "        topicW = r.__getitem__('topicWords')\n",
    "        for w in topicW:\n",
    "            list_of_topics.append(w)\n",
    "\n",
    "    #returns list of 3 'hashtags' i.e keywords for topic\n",
    "    #from tokens: title, brand, cpu_brand\n",
    "    def get_key(words):\n",
    "        l = [w for w in words if w in list_of_topics]\n",
    "        l = list(set(l))\n",
    "        l.sort()\n",
    "        return l[:3]\n",
    "    udf_get_key = f.udf(get_key, t.ArrayType(t.StringType()))\n",
    "    output = output.withColumn(\"blocking_key\", udf_get_key(f.col(\"tokens_swRemoved\")))\n",
    "    output.select(\"blocking_key\").show()\n",
    "    return output\n",
    "\n",
    "\"\"\"Use universal sentence encoder from tensorflow_hub\"\"\"\n",
    "MODEL = None\n",
    "def get_model_magic():\n",
    "  global MODEL\n",
    "  if MODEL is None:\n",
    "      MODEL = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "  return MODEL\n",
    "\n",
    "@f.udf(returnType=VectorUDT())\n",
    "def encode_sentence(x):\n",
    "  model = get_model_magic()\n",
    "  emb = model([x]).numpy()[0]\n",
    "  return Vectors.dense(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['title', 'brand', 'cpu_brand', 'cpu_model', 'ram_type', 'ram_capacity', 'hdd_capacity', 'weight']\n",
    "blocking_df = tokenize(df, columns[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        blocking_key|\n",
      "+--------------------+\n",
      "|  [lenovo, thinkpad]|\n",
      "|      [acer, aspire]|\n",
      "|[acer, aspire, dr...|\n",
      "|                [hp]|\n",
      "|                  []|\n",
      "|[drive, lenovo, t...|\n",
      "|      [acer, aspire]|\n",
      "|      [acer, aspire]|\n",
      "|[drive, lenovo, t...|\n",
      "|      [acer, aspire]|\n",
      "|    [dell, inspiron]|\n",
      "|[dell, drive, ins...|\n",
      "|    [dell, inspiron]|\n",
      "|      [acer, aspire]|\n",
      "|      [acer, aspire]|\n",
      "|      [acer, aspire]|\n",
      "|  [lenovo, thinkpad]|\n",
      "|    [dell, inspiron]|\n",
      "|      [acer, aspire]|\n",
      "|      [acer, aspire]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generate Blocking Keys\n",
    "#for c in columns:\n",
    "    #blocking_df = blocking_df.withColumn(c+'_encoding', encode_sentence(f.coalesce(f.col(c), f.lit(''))))\n",
    "blocking_df = generate_blocking_keys(blocking_df,\n",
    "                                     [c+'_swRemoved' for c in columns[:2]])\n",
    "\n",
    "#Add encoding on title\n",
    "blocking_df = blocking_df.withColumn('title_encoding', encode_sentence(f.coalesce(f.col('title'), f.lit(''))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|        blocking_key|count|\n",
      "+--------------------+-----+\n",
      "|[acer, aspire, home]|   22|\n",
      "|[dell, drive, ins...|    4|\n",
      "|                  []|    2|\n",
      "|[acer, aspire, dr...|    7|\n",
      "|[downgrade, elite...|    2|\n",
      "|[elitebook, hp, pro]|    2|\n",
      "|      [acer, aspire]|   32|\n",
      "|[downgrade, lenov...|   28|\n",
      "|[home, lenovo, th...|    3|\n",
      "|[drive, lenovo, t...|    2|\n",
      "|[elitebook, folio...|    8|\n",
      "|[lenovo, pro, thi...|  120|\n",
      "|         [drive, hp]|    1|\n",
      "|            [lenovo]|    1|\n",
      "|                [hp]|    7|\n",
      "|    [dell, inspiron]|    5|\n",
      "|[carbon, lenovo, ...|   52|\n",
      "|  [lenovo, thinkpad]|    7|\n",
      "|     [elitebook, hp]|   17|\n",
      "|[carbon, downgrad...|   21|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blocking_df.groupby('blocking_key').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Candidate pairs generation and match likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      title_encoding|\n",
      "+--------------------+\n",
      "|[0.01956569217145...|\n",
      "+--------------------+\n",
      "\n",
      "['instance_id', 'brand', 'cpu_brand', 'cpu_model', 'cpu_type', 'cpu_frequency', 'ram_capacity', 'ram_type', 'ram_frequency', 'hdd_capacity', 'weight', 'dimensions', 'title', 'title_swRemoved', 'brand_swRemoved', 'tokens_swRemoved', 'rawFeatures', 'features', 'tfidf', 'blocking_key', 'title_encoding']\n",
      "+--------------------+--------------------+\n",
      "|        blocking_key|                  id|\n",
      "+--------------------+--------------------+\n",
      "|[acer, aspire, home]|       buy.net//1992|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|       buy.net//2012|\n",
      "|[acer, aspire, home]|        buy.net//634|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.amazon.com//1664|\n",
      "|[acer, aspire, home]|www.amazon.com//1081|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.amazon.com//2395|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|       buy.net//1759|\n",
      "|[acer, aspire, home]|www.amazon.com//1313|\n",
      "|[acer, aspire, home]|www.flexshopper.c...|\n",
      "|[acer, aspire, home]|www.amazon.com//1545|\n",
      "|[acer, aspire, home]|        buy.net//393|\n",
      "|[acer, aspire, home]|         buy.net//93|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell output a candidates dataframe that has\n",
    "instance_ids pairs that makes sense to compare, i.e each\n",
    "entity will be paired with another entity from the same block\n",
    "\"\"\"\n",
    "#cols_to_keep = [c+'_encoding' for c in columns]\n",
    "#for c in columns:\n",
    "#    cols_to_keep.append(c)\n",
    "#cols_to_keep.append('tokens_swRemoved')\n",
    "#cols_to_keep.append('tfidf')\n",
    "#cols_to_keep.append('instance_id')\n",
    "cols_to_keep = ['instance_id', 'title_encoding']\n",
    "#node = blocking_df.select(f.col('instance_id').alias('id'), *cols_to_keep).drop('instance_id')\n",
    "node = blocking_df.select(f.col('instance_id').alias('id'), 'title_encoding').drop('instance_id')\n",
    "node.select('title_encoding').limit(1).show()\n",
    "print(blocking_df.columns)\n",
    "pairs = blocking_df.select(*cols_to_keep, 'blocking_key')\\\n",
    "    .groupby('blocking_key').agg(f.count('instance_id').alias('size'), f.collect_set('instance_id').alias('id'))\\\n",
    "    .filter(f.col('size') > 1).select('blocking_key',f.explode('id').alias('id'))\n",
    "pairs.show()\n",
    "\n",
    "left = pairs.withColumnRenamed('id', 'src')\n",
    "right = pairs.withColumnRenamed('id', 'dst')\n",
    "#candidates based on matching of blocking_key (i.e inside the block)\n",
    "candidates = left.join(right, ['blocking_key'], 'inner')\\\n",
    "    .filter(f.col('src') < f.col('dst'))\\\n",
    "    .select('src', 'dst').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\n@f.udf(returnType=t.DoubleType())\\ndef dot(x, y):\\n  if x is not None and y is not None:\\n    return float(x.dot(y))\\n  else:\\n    return 0\\n\\ndef null_safe_levenshtein_sim(c1, c2):\\n  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)            .otherwise(1 - f.levenshtein(c1, c2) / f.greatest(f.length(c1), f.length(c2)))\\n  return output\\n\\ndef null_safe_num_sim(c1, c2):\\n  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)            .when((f.col(c1) == 0) & (f.col(c2) == 0), 1)            .when((f.col(c1) == 0) | (f.col(c2) == 0), 0)            .otherwise(1 - f.abs(f.col(c1) - f.col(c2)) / f.greatest(c1, c2))\\n  return output\\n\\ndef null_safe_token_overlap(c1, c2):\\n  # is the overlap a significant part of the shorter string\\n  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)            .when((f.size(f.array_distinct(c1)) == 0) | (f.size(f.array_distinct(c2)) == 0), 0)            .otherwise(f.size(f.array_intersect(c1, c2)) / f.least(f.size(f.array_distinct(c1)), f.size(f.array_distinct(c1))))\\n  return output\\n\\ndef calc_sim(df, candidates):\\n    metrics = []\\n    for c in columns[:2]:\\n        if '_encoding' not in c:\\n            candidates = candidates.withColumn(c+'_lev', null_safe_levenshtein_sim(df.filter(df.id == candidates.src).select(c),df.filter(df.id == candidates.dst).select(c)))\\n            metrics.append(c+'_lev')\\n        else:\\n            metrics.append(c+'_sim')\\n            candidates = candidates.withColumn(c+'_sim', dot(df.filter(df.id == candidates.src).select(c), df.filter(df.id == candidates.dst).select(c)))\\n    candidates = candidates.withColumn('tfidf_sim', dot(df.filter(df.id == candidates.src).select('tfidf'),df.filter(df.id == candidates.dst).select('tfidf')))\\n    candidates = candidates.withColumn('token_sim', dot(df.filter(df.id == candidates.src).select('tokens_swRemoved'), df.filter(df.id == candidates.dst).select('tokens_swRemoved')))\\n    candidates = candidates.withColumn('weight_sim', dot(df.filter(df.id == candidates.src).select('weight'),df.filter(df.id == candidates.dst).select('weight')))\\n    metrics.append('tfidf_sim')\\n    metrics.append('token_sim')\\n    metrics.append('weigth_sim')\\n    def sum_distance(distances):\\n        return sum(d for d in distances)\\n    udf_sum = f.udf(sum_distance, t.DoubleType())\\n    candidates = candidates.withColumn('sum_sim', udf_sum([f.col(c) for c in metrics]))\\n    udf_norm = f.udf(lambda d : d / len(metrics))\\n    candidates = candidates.withColumn('overall_sim', udf_norm(f.col('sum_sim'))).drop(f.col('sum_sim'))\\n    return candidates\\n\\ndistance_df = calc_sim(node, candidates)\\n\""
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@f.udf(returnType=t.DoubleType())\n",
    "def dot(x, y):\n",
    "  if x is not None and y is not None:\n",
    "    return float(x.dot(y))\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "def null_safe_levenshtein_sim(c1, c2):\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .otherwise(1 - f.levenshtein(c1, c2) / f.greatest(f.length(c1), f.length(c2)))\n",
    "  return output\n",
    "\n",
    "def null_safe_num_sim(c1, c2):\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .when((f.col(c1) == 0) & (f.col(c2) == 0), 1)\\\n",
    "            .when((f.col(c1) == 0) | (f.col(c2) == 0), 0)\\\n",
    "            .otherwise(1 - f.abs(f.col(c1) - f.col(c2)) / f.greatest(c1, c2))\n",
    "  return output\n",
    "\n",
    "def null_safe_token_overlap(c1, c2):\n",
    "  # is the overlap a significant part of the shorter string\n",
    "  output = f.when(f.col(c1).isNull() | f.col(c2).isNull(), 0)\\\n",
    "            .when((f.size(f.array_distinct(c1)) == 0) | (f.size(f.array_distinct(c2)) == 0), 0)\\\n",
    "            .otherwise(f.size(f.array_intersect(c1, c2)) / f.least(f.size(f.array_distinct(c1)), f.size(f.array_distinct(c1))))\n",
    "  return output\n",
    "\n",
    "def calc_sim(df, candidates):\n",
    "    metrics = []\n",
    "    for c in columns[:2]:\n",
    "        if '_encoding' not in c:\n",
    "            candidates = candidates.withColumn(c+'_lev', null_safe_levenshtein_sim(df.filter(df.id == candidates.src).select(c),df.filter(df.id == candidates.dst).select(c)))\n",
    "            metrics.append(c+'_lev')\n",
    "        else:\n",
    "            metrics.append(c+'_sim')\n",
    "            candidates = candidates.withColumn(c+'_sim', dot(df.filter(df.id == candidates.src).select(c), df.filter(df.id == candidates.dst).select(c)))\n",
    "    candidates = candidates.withColumn('tfidf_sim', dot(df.filter(df.id == candidates.src).select('tfidf'),df.filter(df.id == candidates.dst).select('tfidf')))\n",
    "    candidates = candidates.withColumn('token_sim', dot(df.filter(df.id == candidates.src).select('tokens_swRemoved'), df.filter(df.id == candidates.dst).select('tokens_swRemoved')))\n",
    "    candidates = candidates.withColumn('weight_sim', dot(df.filter(df.id == candidates.src).select('weight'),df.filter(df.id == candidates.dst).select('weight')))\n",
    "    metrics.append('tfidf_sim')\n",
    "    metrics.append('token_sim')\n",
    "    metrics.append('weigth_sim')\n",
    "    def sum_distance(distances):\n",
    "        return sum(d for d in distances)\n",
    "    udf_sum = f.udf(sum_distance, t.DoubleType())\n",
    "    candidates = candidates.withColumn('sum_sim', udf_sum([f.col(c) for c in metrics]))\n",
    "    udf_norm = f.udf(lambda d : d / len(metrics))\n",
    "    candidates = candidates.withColumn('overall_sim', udf_norm(f.col('sum_sim'))).drop(f.col('sum_sim'))\n",
    "    return candidates\n",
    "\n",
    "distance_df = calc_sim(node, candidates)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+\n",
      "|                 lid|                 rid|label|\n",
      "+--------------------+--------------------+-----+\n",
      "|www.flexshopper.c...|www.amazon.com//1389|    1|\n",
      "| www.amazon.com//291|www.amazon.com//1081|    1|\n",
      "|        buy.net//634|www.amazon.com//1014|    1|\n",
      "|www.amazon.com//2395|        buy.net//393|    1|\n",
      "|www.flexshopper.c...|        buy.net//634|    1|\n",
      "|www.amazon.com//1313| www.amazon.com//291|    1|\n",
      "|www.amazon.com//1313|www.amazon.com//1014|    1|\n",
      "|www.amazon.com//1081|www.amazon.com//2395|    1|\n",
      "|www.amazon.com//1081|www.amazon.com//1389|    1|\n",
      "| www.amazon.com//291|www.flexshopper.c...|    1|\n",
      "|www.amazon.com//1014|www.amazon.com//1389|    1|\n",
      "| www.amazon.com//291|        buy.net//393|    1|\n",
      "|www.amazon.com//2395|www.amazon.com//1389|    1|\n",
      "|www.amazon.com//1313|www.amazon.com//1081|    1|\n",
      "|www.amazon.com//1081|www.amazon.com//2226|    1|\n",
      "|        buy.net//634|www.flexshopper.c...|    1|\n",
      "|www.amazon.com//1014|www.amazon.com//2226|    1|\n",
      "|        buy.net//393|www.amazon.com//1389|    1|\n",
      "|www.flexshopper.c...| www.amazon.com//291|    1|\n",
      "|www.flexshopper.c...|www.amazon.com//2395|    1|\n",
      "+--------------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "dictionary = {}\n",
    "def countNum(row):\n",
    "   if row.lid in dictionary.keys():\n",
    "       dictionary[row.lid].add(row.rid)\n",
    "   else:\n",
    "       dictionary[row.lid] = set([row.rid, row.lid])\n",
    "\n",
    "   if row.rid in dictionary.keys():\n",
    "       dictionary[row.rid].add(row.lid)\n",
    "   else:\n",
    "       dictionary[row.rid] = set([row.lid, row.rid])\n",
    "\n",
    "\n",
    "labels = spark.read.csv(\"data/Y2.csv\", header=True).withColumnRenamed('left_instance_id', 'lid').withColumnRenamed('right_instance_id', 'rid')\n",
    "filter_label = labels.filter(labels.label == '1')\n",
    "collected_filtered = filter_label.collect()\n",
    "for row in collected_filtered:\n",
    "    countNum(row)\n",
    "f = open('./data/tmp.csv', 'w+')\n",
    "csv_writer = csv.writer(f)\n",
    "csv_writer.writerow(['lid','rid','label'])\n",
    "for key in dictionary.keys():\n",
    "    elem_set = dictionary[key]\n",
    "    while len(elem_set) > 0:\n",
    "        first_elem = elem_set.pop()\n",
    "        for second_elem in elem_set:\n",
    "            if first_elem != second_elem:\n",
    "                l = [first_elem, second_elem, '1']\n",
    "                csv_writer.writerow(l)\n",
    "                if key == first_elem:\n",
    "                    continue\n",
    "                if first_elem in dictionary.keys() and second_elem in dictionary[first_elem]:\n",
    "                    dictionary[first_elem].remove(second_elem)\n",
    "f.close()\n",
    "updated_labels = spark.read.csv(\"data/tmp.csv\", header=True)\n",
    "labels = labels.union(updated_labels)\n",
    "print(labels.count())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lid', 'rid', 'label', 'l_title_encoding', 'r_title_encoding']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#label_df = labels.join(candidates.withColumnRenamed('src','lid').withColumnRenamed('dst','rid'), ['lid','rid'], 'inner')\n",
    "label_df = labels.join(node.alias(\"node_1\"), labels.lid == node.id, 'inner').drop('id')\n",
    "for c in cols_to_keep[1:]:\n",
    "    label_df = label_df.withColumnRenamed(c, 'l_'+c)\n",
    "\n",
    "label_df = label_df.alias('one').join(node.alias(\"node_2\"), label_df.rid == node.id, 'inner').drop('id')\n",
    "for c in cols_to_keep[1:]:\n",
    "    label_df = label_df.withColumnRenamed(c, 'r_'+c)\n",
    "print(label_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def toList(row):\n",
    "    l = []\n",
    "    for v in row:\n",
    "        for n in v:\n",
    "            l.append(float(n))\n",
    "    return Vectors.dense(l)\n",
    "\n",
    "udf_toList = f.udf(toList, VectorUDT())\n",
    "label_df = label_df.withColumn('features', udf_toList(f.array('l_title_encoding', 'r_title_encoding')))\\\n",
    "    .drop('l_title_encoding', 'r_title_encoding')\n",
    "label_df = label_df.withColumn('label', f.col('label').cast(t.IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning Magic Bitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LinearSVC, LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "model = LinearSVC(featuresCol='features', labelCol='label', maxIter=500)\n",
    "param_grid = ParamGridBuilder().addGrid(model.regParam, [0.5, 0.4, 0.3, 0.2, 0.1, 0.02, 0.01]).build()\n",
    "tvs = CrossValidator(estimator=model,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),#(rawPredictionCol='prediction', labelCol='label'),\\\n",
    "                           numFolds=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "training_set, test_set = label_df.randomSplit([0.8, 0.2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#grid_search, hyperpar tuning...\n",
    "estimator = tvs.fit(training_set)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "prediction = estimator.transform(test_set).select('lid','rid','label','prediction')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-----+----------+\n",
      "|                 lid|                 rid|label|prediction|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "|       buy.net//1960|www.vology.com//4272|    1|       0.0|\n",
      "|        buy.net//243|       buy.net//2109|    1|       0.0|\n",
      "|        buy.net//370| www.vology.com//668|    1|       0.0|\n",
      "|        buy.net//393|www.amazon.com//1389|    1|       0.0|\n",
      "|        buy.net//634|www.amazon.com//1389|    1|       0.0|\n",
      "|         buy.net//93|       buy.net//1759|    1|       0.0|\n",
      "|www.amazon.com//1014|www.amazon.com//2226|    1|       0.0|\n",
      "|www.amazon.com//1081|www.amazon.com//1014|    1|       0.0|\n",
      "|www.amazon.com//1081|www.flexshopper.c...|    1|       0.0|\n",
      "|www.amazon.com//1652|www.isupplyhub.co...|    1|       0.0|\n",
      "|www.amazon.com//1671|www.isupplyhub.co...|    1|       0.0|\n",
      "|www.amazon.com//1780|www.amazon.com//1836|    1|       0.0|\n",
      "|www.amazon.com//1780| www.amazon.com//753|    1|       0.0|\n",
      "|www.amazon.com//1835|www.isupplyhub.co...|    1|       0.0|\n",
      "|www.amazon.com//1836| www.amazon.com//241|    1|       0.0|\n",
      "|www.amazon.com//2005| www.amazon.com//953|    1|       0.0|\n",
      "|www.amazon.com//2005|www.isupplyhub.co...|    1|       0.0|\n",
      "|www.amazon.com//2284|www.flexshopper.c...|    1|       0.0|\n",
      "|www.amazon.com//2284|www.flexshopper.c...|    1|       0.0|\n",
      "|www.amazon.com//2395|www.amazon.com//2226|    1|       0.0|\n",
      "| www.amazon.com//241|www.amazon.com//2191|    1|       0.0|\n",
      "| www.amazon.com//279|       buy.net//1836|    1|       0.0|\n",
      "| www.amazon.com//291|www.amazon.com//1081|    1|       0.0|\n",
      "| www.amazon.com//291|www.amazon.com//2395|    1|       0.0|\n",
      "| www.amazon.com//291|www.flexshopper.c...|    1|       0.0|\n",
      "| www.amazon.com//372| www.amazon.com//753|    1|       0.0|\n",
      "|www.flexshopper.c...|        buy.net//393|    1|       0.0|\n",
      "|www.flexshopper.c...| www.vology.com//401|    1|       0.0|\n",
      "|www.flexshopper.c...|www.vology.com//1290|    1|       0.0|\n",
      "|www.flexshopper.c...|www.vology.com//3635|    1|       0.0|\n",
      "|www.flexshopper.c...|        buy.net//634|    1|       0.0|\n",
      "|www.flexshopper.c...|       buy.net//1759|    1|       0.0|\n",
      "|www.flexshopper.c...|www.isupplyhub.co...|    1|       0.0|\n",
      "|www.flexshopper.c...|www.softwarecity....|    1|       0.0|\n",
      "|www.flexshopper.c...|www.vology.com//1277|    1|       0.0|\n",
      "|www.flexshopper.c...| www.vology.com//235|    1|       0.0|\n",
      "|www.flexshopper.c...| www.vology.com//807|    1|       0.0|\n",
      "|www.flexshopper.c...|        buy.net//132|    1|       0.0|\n",
      "|www.flexshopper.c...| www.vology.com//439|    1|       0.0|\n",
      "|www.flexshopper.c...| www.vology.com//521|    1|       0.0|\n",
      "|www.flexshopper.c...| www.vology.com//826|    1|       0.0|\n",
      "|www.isupplyhub.co...|www.flexshopper.c...|    1|       0.0|\n",
      "|www.isupplyhub.co...|       buy.net//1836|    1|       0.0|\n",
      "|www.isupplyhub.co...|www.flexshopper.c...|    1|       0.0|\n",
      "|www.isupplyhub.co...|       buy.net//1963|    1|       0.0|\n",
      "|www.isupplyhub.co...|www.isupplyhub.co...|    1|       0.0|\n",
      "|www.isupplyhub.co...|www.amazon.com//1645|    1|       0.0|\n",
      "|www.isupplyhub.co...| www.amazon.com//398|    1|       0.0|\n",
      "|www.vology.com//1001|www.vology.com//1485|    1|       0.0|\n",
      "|www.vology.com//1001|www.vology.com//1870|    1|       0.0|\n",
      "|www.vology.com//1001|www.vology.com//2085|    1|       0.0|\n",
      "|www.vology.com//1001| www.vology.com//224|    1|       0.0|\n",
      "|www.vology.com//1001| www.vology.com//248|    1|       0.0|\n",
      "|www.vology.com//1001|www.vology.com//4475|    1|       0.0|\n",
      "|www.vology.com//1001| www.vology.com//457|    1|       0.0|\n",
      "|www.vology.com//1004|www.vology.com//1277|    1|       0.0|\n",
      "|www.vology.com//1004|www.vology.com//3333|    1|       0.0|\n",
      "|www.vology.com//1004|www.vology.com//3901|    1|       0.0|\n",
      "|www.vology.com//1004| www.vology.com//469|    1|       0.0|\n",
      "|www.vology.com//1004|  www.vology.com//80|    1|       0.0|\n",
      "| www.vology.com//103|       buy.net//1960|    1|       0.0|\n",
      "| www.vology.com//103|www.flexshopper.c...|    1|       0.0|\n",
      "| www.vology.com//103|www.vology.com//1956|    1|       0.0|\n",
      "| www.vology.com//103| www.vology.com//235|    1|       0.0|\n",
      "| www.vology.com//103|www.vology.com//3784|    1|       0.0|\n",
      "| www.vology.com//103|www.vology.com//4239|    1|       0.0|\n",
      "| www.vology.com//103|www.vology.com//4272|    1|       0.0|\n",
      "| www.vology.com//103| www.vology.com//439|    1|       0.0|\n",
      "| www.vology.com//103| www.vology.com//469|    1|       0.0|\n",
      "| www.vology.com//105|www.vology.com//3017|    1|       0.0|\n",
      "|www.vology.com//1068|www.vology.com//3641|    1|       0.0|\n",
      "|www.vology.com//1102|www.flexshopper.c...|    1|       0.0|\n",
      "|www.vology.com//1107|www.vology.com//1491|    1|       0.0|\n",
      "|www.vology.com//1107|www.vology.com//3742|    1|       0.0|\n",
      "|www.vology.com//1131| www.vology.com//545|    1|       0.0|\n",
      "|www.vology.com//1134|www.vology.com//1618|    1|       0.0|\n",
      "|www.vology.com//1134|www.vology.com//2140|    1|       0.0|\n",
      "|www.vology.com//1189|www.vology.com//1678|    1|       0.0|\n",
      "|www.vology.com//1273|www.vology.com//1618|    1|       0.0|\n",
      "|www.vology.com//1273|www.vology.com//1810|    1|       0.0|\n",
      "|www.vology.com//1349|www.vology.com//1485|    1|       0.0|\n",
      "|www.vology.com//1349|www.vology.com//2085|    1|       0.0|\n",
      "|www.vology.com//1349|www.vology.com//3189|    1|       0.0|\n",
      "|www.vology.com//1349|www.vology.com//3330|    1|       0.0|\n",
      "|www.vology.com//1349|www.vology.com//4475|    1|       0.0|\n",
      "|www.vology.com//1352|www.vology.com//3778|    1|       0.0|\n",
      "|www.vology.com//1352|www.vology.com//3820|    1|       0.0|\n",
      "|www.vology.com//1352| www.vology.com//457|    1|       0.0|\n",
      "|www.vology.com//1414|www.vology.com//1277|    1|       0.0|\n",
      "|www.vology.com//1414|www.vology.com//1895|    1|       0.0|\n",
      "|www.vology.com//1414|www.vology.com//4239|    1|       0.0|\n",
      "|www.vology.com//1414| www.vology.com//807|    1|       0.0|\n",
      "|www.vology.com//1416|www.vology.com//1945|    1|       0.0|\n",
      "|www.vology.com//1416|www.vology.com//4413|    1|       0.0|\n",
      "|www.vology.com//1416| www.vology.com//842|    1|       0.0|\n",
      "|www.vology.com//1430|        buy.net//370|    1|       0.0|\n",
      "|www.vology.com//1430|www.vology.com//1878|    1|       0.0|\n",
      "|www.vology.com//1430|www.vology.com//2932|    1|       0.0|\n",
      "|www.vology.com//1430|www.vology.com//4190|    1|       0.0|\n",
      "|www.vology.com//1430| www.vology.com//435|    1|       0.0|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = prediction.filter(f.col('label')==f.col('prediction').cast(t.IntegerType())).count() / prediction.count()\n",
    "print(\"Accuracy: \", accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}