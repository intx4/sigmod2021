{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a2066b67",
   "language": "python",
   "display_name": "PyCharm (sigmod-2021)"
  },
  "colab": {
   "name": "ml.ipynb",
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhX7L5OIx5hF"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rfDnkQJVx2Or"
   },
   "source": [
    "!pip install pyspark"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from pyspark) (0.10.9)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "wtFo7aqxxXT9"
   },
   "source": [
    "from pyspark.ml.classification import LinearSVC, GBTClassifier, LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "from pyspark.sql import types as t\n",
    "import numpy as np"
   ],
   "execution_count": 112,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "jIDJtN84xXUF"
   },
   "source": [
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.cores.max\", \"2\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_k-IwNRxcMI"
   },
   "source": [
    "# Read the dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJTY7EtgybkC"
   },
   "source": [
    "Make sure to upload the train datasets generated by the `make-dataset.sh` script before proceeding.\n",
    "Either train using X4 or X3,X2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VaURl3J856tx"
   },
   "source": [
    "!unzip X4.zip\n",
    "df = spark.read.parquet('./X4.parquet')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RGucHhevxXUG"
   },
   "source": [
    "!unzip X2.zip\n",
    "!unzip X3.zip\n",
    "df1 = spark.read.parquet('./X2.parquet')\n",
    "df2 = spark.read.parquet('./X3.parquet')\n",
    "df = df1.unionAll(df2)\n",
    "df.toPandas()"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  X2.zip\r\n",
      "replace X2.parquet/.part-00001-865d672c-b16b-4632-b255-74ba3c1c9779-c000.snappy.parquet.crc? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n",
      "/bin/bash: y: command not found\r\n",
      "Archive:  X3.zip\r\n",
      "replace X3.parquet/part-00000-d48b5338-63f5-48aa-b777-5ec06012bc6b-c000.snappy.parquet? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n",
      "/bin/bash: y: command not found\r\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 features  label\n0       [0.32666666666666666, 1.0, 1.0, 1.0, 0.2407407...      1\n1       [0.5026178010471204, 1.0, 1.0, 0.0, 0.0, 0.0, ...      1\n2       [0.17842323651452285, 1.0, 1.0, 1.0, 0.3611111...      1\n3       [0.7969348659003832, 1.0, 1.0, 1.0, 1.0, 0.0, ...      1\n4       [0.4024896265560166, 1.0, 1.0, 1.0, 0.24074074...      1\n...                                                   ...    ...\n230533  [0.2574850299401198, 1.0, 1.0, 0.0, 0.21428571...      0\n230534  [0.2857142857142857, 1.0, 1.0, 0.0, 0.28205128...      0\n230535  [0.2544378698224852, 1.0, 0.0, 0.0, 0.07999999...      0\n230536  [0.2544378698224852, 1.0, 1.0, 0.0, 0.21428571...      0\n230537  [0.27118644067796616, 1.0, 0.0, 0.0, 0.14, 0.8...      0\n\n[230538 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[0.32666666666666666, 1.0, 1.0, 1.0, 0.2407407...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0.5026178010471204, 1.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.17842323651452285, 1.0, 1.0, 1.0, 0.3611111...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.7969348659003832, 1.0, 1.0, 1.0, 1.0, 0.0, ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0.4024896265560166, 1.0, 1.0, 1.0, 0.24074074...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>230533</th>\n      <td>[0.2574850299401198, 1.0, 1.0, 0.0, 0.21428571...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>230534</th>\n      <td>[0.2857142857142857, 1.0, 1.0, 0.0, 0.28205128...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>230535</th>\n      <td>[0.2544378698224852, 1.0, 0.0, 0.0, 0.07999999...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>230536</th>\n      <td>[0.2544378698224852, 1.0, 1.0, 0.0, 0.21428571...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>230537</th>\n      <td>[0.27118644067796616, 1.0, 0.0, 0.0, 0.14, 0.8...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>230538 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cqzuNQIkzVhO"
   },
   "source": [
    "def stratified_split_train_test(df, frac, label,seed=42):\n",
    "    fractions = df.select(label).distinct().withColumn(\"fraction\", f.lit(frac)).rdd.collectAsMap()\n",
    "    df_frac = df.stat.sampleBy(label, fractions, seed)\n",
    "    df_remaining = df.exceptAll(df_frac)\n",
    "    return df_frac, df_remaining\n",
    "\n",
    "train_set, test_set = stratified_split_train_test(df, 0.8, 'label')\n",
    "\n",
    "def with_weights(df, column=\"label\"):\n",
    "    w_zero = 1 / df.filter(f.col(column) == 0).count()\n",
    "    w_one = 0.8 / df.filter(f.col(column) == 1).count()\n",
    "    return df.withColumn(\"weight\", f.when(f.col(column) == 0, w_zero).otherwise(w_one))\n",
    "\n",
    "train_set = with_weights(train_set)"
   ],
   "execution_count": 104,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "xEY8AmLBxXUI"
   },
   "source": [
    "# Train SVM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6f7R6892zJTE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "model_svc = LinearSVC(weightCol='weight', maxIter=100, predictionCol='prediction_svc')\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(model_svc.threshold, [1.2,1.3,1.4,1.5,1.65,1.7])\\\n",
    "    .build()\n",
    "cvs = CrossValidator(estimator=model_svc,\n",
    "                     estimatorParamMaps=paramGrid,\n",
    "                     evaluator=BinaryClassificationEvaluator(weightCol='weight',metricName='areaUnderPR'),\n",
    "                     numFolds=4)\n",
    "estimator_svc = cvs.fit(train_set_base)"
   ],
   "execution_count": 105,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction and accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = estimator_svc.transform(test_set).select('label', 'prediction')\n",
    "\n",
    "tp = prediction.filter('label == 1 AND prediction == 1').count()\n",
    "rp = prediction.filter('prediction == 1').count()\n",
    "ap = prediction.filter('label == 1').count()\n",
    "\n",
    "p = tp/rp\n",
    "r = tp/ap\n",
    "f = 2 * p * r / (p + r)\n",
    "print(f'F1-score: {f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}