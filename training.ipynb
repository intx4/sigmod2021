{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "ml.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhX7L5OIx5hF"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfDnkQJVx2Or"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wtFo7aqxxXT9"
      },
      "source": [
        "from pyspark.ml.classification import LinearSVC, LogisticRegression\n",
        "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql import types as t\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "jIDJtN84xXUF"
      },
      "source": [
        "spark = (\n",
        "    SparkSession.builder.config(\"spark.executor.memory\", \"4g\")\n",
        "    .config(\"spark.executor.cores\", \"2\")\n",
        "    .config(\"spark.cores.max\", \"2\")\n",
        "    .config(\"spark.driver.memory\", \"8g\")\n",
        "    .getOrCreate()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_k-IwNRxcMI"
      },
      "source": [
        "# Read the dataset(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJTY7EtgybkC"
      },
      "source": [
        "Make sure to upload the train datasets generated by the `make-dataset.sh` script before proceeding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaURl3J856tx"
      },
      "source": [
        "!unzip X4.zip\n",
        "df = spark.read.parquet('./X4.parquet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RGucHhevxXUG"
      },
      "source": [
        "!unzip X2.zip\n",
        "!unzip X3.zip\n",
        "df1 = spark.read.parquet('./X2.parquet')\n",
        "df2 = spark.read.parquet('./X3.parquet')\n",
        "df = df1.union(df2).distinct()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqzuNQIkzVhO"
      },
      "source": [
        "train_set, test_set = df.randomSplit([0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv2w-MBnzbp_"
      },
      "source": [
        "def with_weights(df, column=\"label\"):\n",
        "    w_zero = 1 / df.filter(f.col(column) == 0).count()\n",
        "    w_one = 1 / df.filter(f.col(column) == 1).count()\n",
        "    return df.withColumn(\"weight\", f.when(f.col(column) == 0, w_zero).otherwise(w_one))\n",
        "\n",
        "train_set = with_weights(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xEY8AmLBxXUI"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f7R6892zJTE"
      },
      "source": [
        "model = LinearSVC(threshold=1.1, featuresCol='features', labelCol='label', weightCol='weight', maxIter=100)\n",
        "estimator = model.fit(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGaMgTFnzPmH"
      },
      "source": [
        "# Prediction and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "KIcFS-z1xXUM"
      },
      "source": [
        "prediction = estimator.transform(test_set)\n",
        "accuracy = prediction.filter(f.col('label') == f.col('prediction')).count() / prediction.count()\n",
        "print(\"Accuracy: \", accuracy)\n",
        "\n",
        "tp = prediction.filter(\"label==1 AND prediction==1\").count() \n",
        "p = tp / prediction.filter('prediction==1').count()\n",
        "r = tp / prediction.filter('label == 1').count()\n",
        "f1 = 2 * p * r / (p + r)\n",
        "print(\"F1 score: \", f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmw3oxGK9fdL"
      },
      "source": [
        "#estimator.save(\"model-notebooks\")\n",
        "estimator.save(\"model-products\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5Gkn65MhxXUM"
      },
      "source": [
        "!zip -r models.zip model-notebooks model-products"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcVLH81X5sZu"
      },
      "source": [
        "# Extra: hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "V1QEThFtxXUJ"
      },
      "source": [
        "ths = np.linspace(0.5,1.6,num=22)\n",
        "model = LinearSVC(featuresCol='features', labelCol='label', weightCol='weight',maxIter=100)\n",
        "param_grid = ParamGridBuilder().addGrid(model.threshold, ths).build()\n",
        "cvs_2 = CrossValidator(estimator=model,\n",
        "                           estimatorParamMaps=param_grid,\n",
        "                           evaluator=BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='label', weightCol='weights', metricName=\"areaUnderPR\"),\\\n",
        "                           numFolds=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czjv2X8e_wFS"
      },
      "source": [
        "def stratified_split_train_test(df, frac, label, seed=42):\n",
        "    \"\"\" stratfied split of a dataframe in train and test set.\"\"\"\n",
        "    fractions = df.select(label).distinct().withColumn(\"fraction\", f.lit(frac)).rdd.collectAsMap()\n",
        "    df_frac = df.stat.sampleBy(label, fractions, seed)\n",
        "    df_remaining = df.exceptAll(df_frac)\n",
        "    return df_frac, df_remaining"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "p6N7JCvFxXUJ"
      },
      "source": [
        "\n",
        "#training_set, test_set = stratified_split_train_test(df=label_df, frac=0.8, label=\"label\")\n",
        "#grid_search, hyperpar tuning...\n",
        "training_set, test_set = stratified_split_train_test(df=label_df,label='label',frac=0.8,seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "ssws66o_xXUK"
      },
      "source": [
        "estimator_2 = cvs_2.fit(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": true
        },
        "id": "z_AfjmSrxXUL"
      },
      "source": [
        "prediction_2 = estimator_2.transform(test_set).select('label','prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "QDx6Dor2xXUN"
      },
      "source": [
        "estimator_2.bestModel.getThreshold()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}