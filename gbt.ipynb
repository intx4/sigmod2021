{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "pycharm-a2066b67",
   "language": "python",
   "display_name": "PyCharm (sigmod-2021)"
  },
  "colab": {
   "name": "ml.ipynb",
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhX7L5OIx5hF"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rfDnkQJVx2Or"
   },
   "source": [
    "!pip install pyspark"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /home/intx/PycharmProjects/sigmod21/venv/lib/python3.8/site-packages (from pyspark) (0.10.9)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "wtFo7aqxxXT9"
   },
   "source": [
    "from pyspark.ml.classification import LinearSVC, GBTClassifier, LogisticRegression, LinearSVCModel\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.ml.linalg import VectorUDT, Vectors\n",
    "from pyspark.sql import types as t\n",
    "import numpy as np"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.executor.cores\", \"2\")\n",
    "    .config(\"spark.cores.max\", \"2\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")\n",
    "    .getOrCreate()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_k-IwNRxcMI"
   },
   "source": [
    "# Read the dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJTY7EtgybkC"
   },
   "source": [
    "Make sure to upload the train datasets generated by the `make-dataset.sh` script before proceeding.\n",
    "Either train using X4 or X3,X2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VaURl3J856tx"
   },
   "source": [
    "!unzip X4.zip"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  X4.zip\r\n",
      "replace X4.parquet/.part-00000-34b7377e-848c-4866-bfc8-33e858f2cd38-c000.snappy.parquet.crc? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df = spark.read.parquet('./X4.parquet')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "RGucHhevxXUG"
   },
   "source": [
    "df1 = spark.read.parquet('./X2.parquet')\n",
    "df2 = spark.read.parquet('./X3.parquet')\n",
    "df = df1.unionAll(df2)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.toPandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cqzuNQIkzVhO"
   },
   "source": [
    "def stratified_split_train_test(df, frac, label,seed=42):\n",
    "    fractions = df.select(label).distinct().withColumn(\"fraction\", f.lit(frac)).rdd.collectAsMap()\n",
    "    df_frac = df.stat.sampleBy(label, fractions, seed)\n",
    "    df_remaining = df.exceptAll(df_frac)\n",
    "    return df_frac, df_remaining\n",
    "\n",
    "train_set, test_set = stratified_split_train_test(df, 0.8, 'label')\n",
    "\n",
    "def with_weights(df, column=\"label\"):\n",
    "    w_zero = 1 / df.filter(f.col(column) == 0).count()\n",
    "    w_one = 1 / df.filter(f.col(column) == 1).count()\n",
    "    return df.withColumn(\"weight\", f.when(f.col(column) == 0, w_zero).otherwise(w_one))\n",
    "\n",
    "train_set = with_weights(train_set)\n"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "xEY8AmLBxXUI"
   },
   "source": [
    "# Train the model gbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model = GBTClassifier(weightCol='weight', maxIter=200, predictionCol='prediction')\n",
    "model.setLossType('logistic')\n",
    "model.setMaxDepth(8)\n",
    "model.setMaxBins(28)\n",
    "estimator = model.fit(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model-notebooks': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r model-notebooks\n",
    "estimator.save(\"model-notebooks\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "model = LinearSVC(weightCol='weight', maxIter=1000000, predictionCol='prediction')\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(model.threshold, [1.0,1.1,1.2,1.3,1.4,1.5])\\\n",
    "    .build()\n",
    "\n",
    "cvs = CrossValidator(estimator=model,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                     evaluator=BinaryClassificationEvaluator(weightCol='weight', metricName='areaUnderPR'),\n",
    "                     numFolds=4,\n",
    "                    )\n",
    "model.setThreshold(1.00001)\n",
    "estimator = model.fit(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'model-products': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r model-products\n",
    "estimator.save(\"model-products\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prediction and evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KIcFS-z1xXUM"
   },
   "source": [
    "prediction = estimator.transform(test_set).drop('rawPrediction').drop('probability')\n",
    "\n",
    "tp = prediction.filter(\"label==1 AND prediction==1\").count()\n",
    "p = tp / prediction.filter('prediction==1').count()\n",
    "r = tp / prediction.filter('label == 1').count()\n",
    "f1 = 2 * p * r / (p + r)\n",
    "print(\"precision\", p)\n",
    "print(\"recall\", r)\n",
    "print(\"F1 score: \", f1)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.8635451505016722\n",
      "recall 0.989272030651341\n",
      "F1 score:  0.9221428571428572\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "5Gkn65MhxXUM"
   },
   "source": [
    "!zip -r -9 models.zip model-notebooks"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: model-notebooks/ (stored 0%)\r\n",
      "  adding: model-notebooks/data/ (stored 0%)\r\n",
      "  adding: model-notebooks/data/part-00003-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet (deflated 8%)\r\n",
      "  adding: model-notebooks/data/part-00002-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet (deflated 8%)\r\n",
      "  adding: model-notebooks/data/.part-00000-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/data/.part-00002-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/data/._SUCCESS.crc (stored 0%)\r\n",
      "  adding: model-notebooks/data/.part-00001-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/data/part-00001-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet (deflated 7%)\r\n",
      "  adding: model-notebooks/data/.part-00003-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/data/part-00000-e013ceb3-8ef6-4849-b4fb-f50f8356022e-c000.snappy.parquet (deflated 12%)\r\n",
      "  adding: model-notebooks/data/_SUCCESS (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/ (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/.part-00002-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/.part-00003-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/part-00001-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet (deflated 41%)\r\n",
      "  adding: model-notebooks/treesMetadata/part-00000-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet (deflated 41%)\r\n",
      "  adding: model-notebooks/treesMetadata/part-00003-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet (deflated 41%)\r\n",
      "  adding: model-notebooks/treesMetadata/.part-00001-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/._SUCCESS.crc (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/.part-00000-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet.crc (stored 0%)\r\n",
      "  adding: model-notebooks/treesMetadata/part-00002-500bc961-1afe-4737-9116-a1358f074b2e-c000.snappy.parquet (deflated 43%)\r\n",
      "  adding: model-notebooks/treesMetadata/_SUCCESS (stored 0%)\r\n",
      "  adding: model-notebooks/metadata/ (stored 0%)\r\n",
      "  adding: model-notebooks/metadata/.part-00000.crc (stored 0%)\r\n",
      "  adding: model-notebooks/metadata/part-00000 (deflated 46%)\r\n",
      "  adding: model-notebooks/metadata/._SUCCESS.crc (stored 0%)\r\n",
      "  adding: model-notebooks/metadata/_SUCCESS (stored 0%)\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: model-products/ (stored 0%)\r\n",
      "updating: model-products/data/ (stored 0%)\r\n",
      "updating: model-products/data/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model-products/data/_SUCCESS (stored 0%)\r\n",
      "updating: model-products/metadata/ (stored 0%)\r\n",
      "updating: model-products/metadata/.part-00000.crc (stored 0%)\r\n",
      "updating: model-products/metadata/part-00000 (deflated 44%)\r\n",
      "updating: model-products/metadata/._SUCCESS.crc (stored 0%)\r\n",
      "updating: model-products/metadata/_SUCCESS (stored 0%)\r\n",
      "  adding: model-products/data/part-00000-918217d8-7528-45f5-a751-2dcb8acfe31a-c000.snappy.parquet (deflated 48%)\r\n",
      "  adding: model-products/data/.part-00000-918217d8-7528-45f5-a751-2dcb8acfe31a-c000.snappy.parquet.crc (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r -9 models.zip model-products"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}